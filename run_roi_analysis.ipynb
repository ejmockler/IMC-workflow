{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMC ROI Analysis Pipeline - Stage 1: Per-ROI Processing\n",
    "\n",
    "**Goal:** This notebook processes individual Imaging Mass Cytometry (IMC) ROI files (`.txt` format). For each ROI, it performs:\n",
    "1.  Data loading and validation.\n",
    "2.  Optimal Arcsinh cofactor calculation.\n",
    "3.  Per-channel Arcsinh transformation and scaling.\n",
    "4.  Generation of resolution-independent visualizations (Pixel correlation clustermap, Raw vs. Scaled comparison).\n",
    "5.  Iterates through specified Leiden resolutions:\n",
    "    *   Spatial Leiden clustering on pixel data.\n",
    "    *   Calculation of community profiles (average scaled expression per community).\n",
    "    *   Differential expression analysis between adjacent communities (optional).\n",
    "    *   Generation of resolution-dependent visualizations (Community correlation map, UMAP, Co-expression matrix).\n",
    "6.  Saves processed data (scaled pixel results, community profiles, etc.) and visualizations into ROI-specific output directories.\n",
    "\n",
    "**Methodology:** It utilizes functions imported from the `src.roi_pipeline` modules and leverages `joblib` for parallel processing of ROIs.\n",
    "\n",
    "**Input:**\n",
    "*   Raw IMC `.txt` files located in the directory specified in `config.yaml` (`paths: data_dir`).\n",
    "*   Configuration settings from `config.yaml`.\n",
    "\n",
    "**Output:**\n",
    "*   A structured output directory (specified in `config.yaml`, `paths: output_dir`) containing subdirectories for each processed ROI.\n",
    "*   Within each ROI directory:\n",
    "    *   Cofactor information (`cofactors_*.json`).\n",
    "    *   Resolution-independent plots (`pixel_channel_correlation_*.svg`, `spatial_raw_vs_scaled_matrix_*.svg`).\n",
    "    *   Subdirectories for each processed resolution (e.g., `resolution_0_3/`).\n",
    "        *   Community profiles (`community_profiles_scaled_*.csv`).\n",
    "        *   Differential expression results (optional) (`community_diff_profiles_*.csv`, `community_top_channels_*.csv`).\n",
    "        *   UMAP coordinates (optional) (`umap_coords_*.csv`).\n",
    "        *   Final pixel results with community assignments (`pixel_analysis_results_final_*.csv`).\n",
    "        *   Resolution-dependent plots (`community_channel_correlation_*.svg`, `umap_community_scatter_*.svg`, `coexpression_matrix_scaled_vs_avg_*.svg`).\n",
    "\n",
    "**Next Steps:** The outputs generated by this notebook (specifically the `community_profiles_scaled_*.csv` and `pixel_analysis_results_final_*.csv` files) serve as the primary inputs for the **Experiment-Level Analysis Notebook**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/noot/.pyenv/versions/miniconda3-latest/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported pipeline modules.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import sys\n",
    "import multiprocessing\n",
    "import traceback\n",
    "import gc\n",
    "from typing import List, Tuple, Optional, Dict, Any\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# --- Import Pipeline Modules ---\n",
    "# Encapsulated logic resides in these modules\n",
    "try:\n",
    "    from src.roi_pipeline.imc_data_utils import (\n",
    "        load_and_validate_roi_data,\n",
    "        calculate_optimal_cofactors_for_roi,\n",
    "        apply_per_channel_arcsinh_and_scale,\n",
    "    )\n",
    "    from src.roi_pipeline.pixel_analysis_core import (\n",
    "        run_spatial_leiden,\n",
    "        calculate_and_save_profiles,\n",
    "        calculate_differential_expression # Keep import even if DiffEx is optional via config\n",
    "    )\n",
    "    from src.roi_pipeline.pixel_visualization import (\n",
    "        plot_correlation_clustermap,\n",
    "        plot_umap_scatter, # Requires umap-learn\n",
    "        plot_coexpression_matrix,\n",
    "        plot_raw_vs_scaled_spatial_comparison # Corrected name\n",
    "    )\n",
    "    # Attempt to import UMAP, set flag\n",
    "    try:\n",
    "        import umap\n",
    "        umap_available = True\n",
    "    except ImportError:\n",
    "        print(\"WARNING: package 'umap-learn' not found. UMAP visualization will be skipped.\")\n",
    "        umap_available = False\n",
    "\n",
    "    print(\"Successfully imported pipeline modules.\")\n",
    "except ImportError as e:\n",
    "    print(f\"ERROR: Failed to import pipeline modules. Ensure 'src' is in the Python path.\")\n",
    "    print(f\"Details: {e}\")\n",
    "    # Optionally raise error or exit if imports fail\n",
    "    # raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/noot/IMC'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration\n",
    "\n",
    "Load settings from the central `config.yaml` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded successfully from: config.yaml\n",
      "Config basic validation passed.\n",
      "\n",
      "Key Configuration Parameters:\n",
      "  Data Directory: /Users/noot/Documents/IMC/data/241218_IMC_Alun/\n",
      "  Output Directory: /Users/noot/Documents/IMC/output_plots/\n",
      "  Metadata File: /Users/noot/Documents/IMC/data/Data_annotations_Karen/Metadata-Table 1.csv\n",
      "  Master Protein Channels: ['CD45(Y89Di)', 'Ly6G(Pr141Di)', 'CD11b(Nd143Di)', 'CD140a(Nd148Di)', 'CD140b(Eu151Di)', 'CD31(Sm154Di)', 'CD34(Er166Di)', 'CD206(Tm169Di)', 'CD44(Yb171Di)']\n",
      "  Default Cofactor: 5.0\n",
      "  Differential Expression: False\n",
      "  Non-protein Markers for UMAP: ['80ArAr(ArAr80Di)', '130Ba(Ba130Di)', '131Xe(Xe131Di)', '190BCKG(BCKG190Di)', 'DNA1(Ir191Di)', 'DNA2(Ir193Di)']\n",
      "  UMAP Parameters: 15 neighbors, 0.1 min dist, 8 components\n",
      "  Clustering Seed: 42\n",
      "  Spatial Clustering Parameters: 65 neighbors, [0.3, 0.001] resolution\n"
     ]
    }
   ],
   "source": [
    "CONFIG_PATH = \"config.yaml\" # Or allow user input\n",
    "\n",
    "def load_config(config_path: str) -> Optional[Dict]:\n",
    "    \"\"\"Loads the pipeline configuration from a YAML file.\"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        print(f\"Configuration loaded successfully from: {config_path}\")\n",
    "        # Basic validation (can be expanded)\n",
    "        if not isinstance(config, dict) or not all(k in config for k in ['paths', 'data', 'analysis', 'processing']):\n",
    "            print(f\"ERROR: Config file {config_path} is missing required top-level keys (paths, data, analysis, processing) or is not a valid dictionary.\")\n",
    "            return None\n",
    "        # Validate essential sub-keys\n",
    "        if not config.get('paths',{}).get('data_dir') or not config.get('paths',{}).get('output_dir'):\n",
    "             print(\"ERROR: Config missing paths -> data_dir or paths -> output_dir\")\n",
    "             return None\n",
    "        if not config.get('data', {}).get('master_protein_channels'):\n",
    "             print(\"ERROR: Config missing data -> master_protein_channels\")\n",
    "             return None\n",
    "        print(\"Config basic validation passed.\")\n",
    "        return config\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Configuration file not found at {config_path}\")\n",
    "        return None\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"ERROR: Failed to parse configuration file {config_path}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: An unexpected error occurred while loading configuration: {e}\")\n",
    "        return None\n",
    "\n",
    "# Load the config\n",
    "config = load_config(CONFIG_PATH)\n",
    "\n",
    "# Display some key config values (optional)\n",
    "if config:\n",
    "    print(\"\\nKey Configuration Parameters:\")\n",
    "    print(f\"  Data Directory: {config.get('paths', {}).get('data_dir')}\")\n",
    "    print(f\"  Output Directory: {config.get('paths', {}).get('output_dir')}\")\n",
    "    print(f\"  Metadata File: {config.get('paths', {}).get('metadata_file')}\")\n",
    "    print(f\"  Master Protein Channels: {config.get('data', {}).get('master_protein_channels')}\")\n",
    "    print(f\"  Default Cofactor: {config.get('data', {}).get('default_arcsinh_cofactor')}\")\n",
    "    print(f\"  Differential Expression: {config.get('analysis', {}).get('differential_expression', {}).get('run_differential_expression', False)}\")\n",
    "    print(f\"  Non-protein Markers for UMAP: {config.get('analysis', {}).get('differential_expression', {}).get('non_protein_markers_for_umap', [])}\")\n",
    "    print(f\"  UMAP Parameters: {config.get('analysis', {}).get('umap', {}).get('n_neighbors', 'Not Set')} neighbors, {config.get('analysis', {}).get('umap', {}).get('min_dist', 'Not Set')} min dist, {config.get('analysis', {}).get('umap', {}).get('n_components', 'Not Set')} components\")\n",
    "    print(f\"  Clustering Seed: {config.get('analysis', {}).get('clustering', {}).get('seed', 'Not Set')}\")\n",
    "    print(f\"  Spatial Clustering Parameters: {config.get('analysis', {}).get('clustering', {}).get('n_neighbors', 'Not Set')} neighbors, {config.get('analysis', {}).get('clustering', {}).get('resolution_params', 'Not Set')} resolution\")    \n",
    "\n",
    "    # Add more relevant parameters as needed\n",
    "else:\n",
    "    print(\"\\nStopping notebook execution due to configuration loading error.\")\n",
    "    # Consider raising an error or using sys.exit() if running non-interactively\n",
    "    # raise ValueError(\"Failed to load configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the Core ROI Processing Function (`analyze_roi`)\n",
    "\n",
    "This function encapsulates the entire analysis workflow for a *single* ROI file. It calls the underlying functions imported from our pipeline modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_resolution_independent_visualizations(roi_raw_data: pd.DataFrame,\n",
    "                                                 scaled_pixel_expression: pd.DataFrame,\n",
    "                                                 roi_channels: List[str],\n",
    "                                                 roi_cofactors: Dict[str, float],\n",
    "                                                 roi_output_dir: str, # Main ROI output dir\n",
    "                                                 roi_string: str,\n",
    "                                                 config: Dict) -> Optional[List[str]]: # Return the channel order\n",
    "    \"\"\"Generates plots that do not depend on Leiden resolution. Returns channel order from pixel clustermap.\"\"\"\n",
    "    print(\"\\nGenerating resolution-independent visualizations...\")\n",
    "    start_time_viz = time.time()\n",
    "    cfg_processing = config['processing']\n",
    "    cfg_viz = cfg_processing['visualization']\n",
    "    ordered_channels_from_pixel_corr = None # Initialize\n",
    "\n",
    "    # --- Pixel-Level Correlation Clustermap ---\n",
    "    print(\"   Generating pixel-level correlation clustermap...\")\n",
    "    if not scaled_pixel_expression.empty and not scaled_pixel_expression.isnull().values.any():\n",
    "        try:\n",
    "            pixel_correlation_matrix = scaled_pixel_expression.corr(method='spearman')\n",
    "            pixel_corr_heatmap_path = os.path.join(roi_output_dir, f\"pixel_channel_correlation_heatmap_spearman_{roi_string}.svg\") # Changed extension\n",
    "            # Capture the returned order\n",
    "            ordered_channels_from_pixel_corr = plot_correlation_clustermap(\n",
    "                 correlation_matrix=pixel_correlation_matrix,\n",
    "                 channels=roi_channels,\n",
    "                 title=f'Pixel Channel Correlation (Spearman, Asinh Scaled) - {roi_string}',\n",
    "                 output_path=pixel_corr_heatmap_path,\n",
    "                 plot_dpi=cfg_processing['plot_dpi']\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"   WARNING: Failed to generate pixel correlation map: {e}\")\n",
    "    else:\n",
    "         print(\"   Skipping pixel correlation analysis: Scaled pixel data is empty or contains NaNs.\")\n",
    "    # Fallback if order couldn't be determined\n",
    "    if ordered_channels_from_pixel_corr is None:\n",
    "        ordered_channels_from_pixel_corr = roi_channels # Use original order\n",
    "        print(\"   Warning: Could not determine channel order from pixel correlation, using original order.\")\n",
    "\n",
    "    # --- NEW: Raw vs Scaled Spatial Expression Matrix ---\n",
    "    print(\"   Generating Raw vs Scaled Spatial Expression Matrix...\")\n",
    "    if not roi_raw_data.empty and not scaled_pixel_expression.empty:\n",
    "        try:\n",
    "            raw_vs_scaled_plot_path = os.path.join(roi_output_dir, f\"spatial_raw_vs_scaled_matrix_{roi_string}.svg\")\n",
    "            # Using the ordered channels if available\n",
    "            plot_raw_vs_scaled_spatial_comparison(\n",
    "                roi_raw_data=roi_raw_data,\n",
    "                scaled_pixel_expression=scaled_pixel_expression,\n",
    "                roi_channels=ordered_channels_from_pixel_corr, # Use ordered channels\n",
    "                config=config,\n",
    "                output_path=raw_vs_scaled_plot_path,\n",
    "                roi_string=roi_string\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"   WARNING: Failed to generate Raw vs Scaled spatial matrix: {e}\")\n",
    "            traceback.print_exc() # Print stack trace for debugging\n",
    "    else:\n",
    "        print(\"   Skipping Raw vs Scaled spatial matrix: Raw or Scaled data is empty.\")\n",
    "\n",
    "    print(f\"--- Resolution-independent visualizations finished in {time.time() - start_time_viz:.2f} seconds ---\")\n",
    "    return ordered_channels_from_pixel_corr # Return the order for downstream use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generate_resolution_dependent_visualizations(pixel_results_df: pd.DataFrame, # Resolution specific df, contains coords, community, scaled values, mapped avg values\n",
    "                                               scaled_pixel_expression: pd.DataFrame, # Original scaled pixel data\n",
    "                                               scaled_community_profiles: pd.DataFrame,\n",
    "                                               diff_expr_profiles: Optional[pd.DataFrame],\n",
    "                                               distinguishing_channel_map: Optional[pd.Series],\n",
    "                                               roi_channels: List[str], # Original channel list\n",
    "                                               ordered_channels: List[str], # Channel list ordered by pixel corr\n",
    "                                               roi_cofactors: Dict[str, float],\n",
    "                                               resolution_output_dir: str, # Resolution specific dir\n",
    "                                               roi_string: str,\n",
    "                                               resolution_param: float,\n",
    "                                               config: Dict):\n",
    "    \"\"\"Generates plots that depend on the specific Leiden resolution.\"\"\"\n",
    "    print(f\"\\nGenerating resolution-dependent visualizations (Resolution: {resolution_param})...\")\n",
    "    start_time_viz = time.time()\n",
    "    cfg_processing = config['processing']\n",
    "    cfg_analysis = config['analysis']\n",
    "    cfg_viz = cfg_processing['visualization']\n",
    "    res_suffix = f\"_res_{resolution_param}\"\n",
    "\n",
    "    # --- Community-Level Correlation Clustermap (Use original roi_channels) ---\n",
    "    print(\"   Generating community-level correlation clustermap...\")\n",
    "    if not scaled_community_profiles.empty:\n",
    "        try:\n",
    "            community_correlation_matrix = scaled_community_profiles.corr(method='spearman')\n",
    "            comm_corr_heatmap_path = os.path.join(resolution_output_dir, f\"community_channel_correlation_heatmap_spearman_{roi_string}{res_suffix}.svg\") # Changed extension\n",
    "            # We don't necessarily want this ordered by pixel correlation, so use original roi_channels\n",
    "            plot_correlation_clustermap(\n",
    "                 correlation_matrix=community_correlation_matrix,\n",
    "                 channels=roi_channels, # Use original list here\n",
    "                 title=f'Community Corr (Spearman, Avg. Scaled) - {roi_string} (Res: {resolution_param})',\n",
    "                 output_path=comm_corr_heatmap_path,\n",
    "                 plot_dpi=cfg_processing['plot_dpi']\n",
    "            ) # We don't need the order returned here\n",
    "        except Exception as e:\n",
    "            print(f\"   WARNING: Failed to generate community correlation map: {e}\")\n",
    "    else:\n",
    "        print(\"   Skipping community correlation analysis: Scaled community profiles empty.\")\n",
    "\n",
    "    # --- UMAP on Differential Profiles & Plot (Uses roi_channels for filtering) ---\n",
    "    umap_coords = None # Define umap_coords before the block\n",
    "    if umap_available and diff_expr_profiles is not None and not diff_expr_profiles.empty:\n",
    "        print(\"\\n   Running UMAP and plotting communities...\")\n",
    "        try:\n",
    "            non_protein_markers = cfg_analysis['differential_expression'].get('non_protein_markers_for_umap', [])\n",
    "            protein_marker_channels_for_umap = [\n",
    "                ch for ch in diff_expr_profiles.columns\n",
    "                if ch in roi_channels and ch not in non_protein_markers # Filter based on original channels\n",
    "            ]\n",
    "            if not protein_marker_channels_for_umap:\n",
    "                print(\"      Skipping UMAP: No protein marker channels found.\")\n",
    "            else:\n",
    "                diff_data_for_umap = diff_expr_profiles[protein_marker_channels_for_umap].copy()\n",
    "                communities_in_order = diff_expr_profiles.index.tolist()\n",
    "                if diff_data_for_umap.isnull().values.any() or np.isinf(diff_data_for_umap.values).any():\n",
    "                     print(\"      Warning: NaN/Inf values found. Replacing with 0.\")\n",
    "                     diff_data_for_umap = diff_data_for_umap.fillna(0).replace([np.inf, -np.inf], 0)\n",
    "\n",
    "                n_communities = len(diff_data_for_umap)\n",
    "                umap_n_neighbors = min(cfg_analysis['umap']['n_neighbors'], n_communities - 1) if n_communities > 1 else 1\n",
    "                current_umap_n_components = max(2, cfg_analysis['umap']['n_components'])\n",
    "\n",
    "                if n_communities > umap_n_neighbors and n_communities >= current_umap_n_components:\n",
    "                     try:\n",
    "                         umap_reducer = umap.UMAP(\n",
    "                             n_neighbors=umap_n_neighbors,\n",
    "                             min_dist=cfg_analysis['umap']['min_dist'],\n",
    "                             n_components=current_umap_n_components,\n",
    "                             metric=cfg_analysis['umap']['metric'],\n",
    "                             random_state=cfg_analysis['clustering']['seed']\n",
    "                         )\n",
    "                         embedding = umap_reducer.fit_transform(diff_data_for_umap.values)\n",
    "                         umap_component_names = [f'UMAP{i+1}' for i in range(current_umap_n_components)]\n",
    "                         umap_coords = pd.DataFrame(embedding, index=communities_in_order, columns=umap_component_names)\n",
    "                         umap_coords_path = os.path.join(resolution_output_dir, f\"umap_coords_diff_profiles_{roi_string}{res_suffix}.csv\") # Keep CSV for coords\n",
    "                         umap_coords.to_csv(umap_coords_path)\n",
    "                         print(f\"      UMAP coordinates saved to: {os.path.basename(umap_coords_path)}\")\n",
    "\n",
    "                         if distinguishing_channel_map is not None and not distinguishing_channel_map.empty:\n",
    "                             umap_scatter_path = os.path.join(resolution_output_dir, f\"umap_community_scatter_protein_markers_diff_profiles_{roi_string}{res_suffix}.svg\") # Changed extension\n",
    "                             plot_umap_scatter(\n",
    "                                 umap_coords=umap_coords,\n",
    "                                 community_top_channel_map=distinguishing_channel_map,\n",
    "                                 protein_marker_channels=protein_marker_channels_for_umap,\n",
    "                                 roi_string=f\"{roi_string} (Res: {resolution_param})\",\n",
    "                                 output_path=umap_scatter_path,\n",
    "                                 plot_dpi=cfg_processing['plot_dpi']\n",
    "                             )\n",
    "                         else:\n",
    "                             print(\"      Skipping UMAP scatter plot: Missing distinguishing channel map.\")\n",
    "\n",
    "                     except Exception as umap_err:\n",
    "                          print(f\"      ERROR during UMAP embedding or plotting: {umap_err}\")\n",
    "                          umap_coords = None\n",
    "                else:\n",
    "                     print(f\"      Skipping UMAP embedding: Not enough communities ({n_communities}) vs neighbors/components.\")\n",
    "        except Exception as e:\n",
    "            print(f\"   WARNING: Failed during UMAP step: {e}\")\n",
    "    elif not umap_available:\n",
    "        print(\"\\n   Skipping UMAP visualization: umap-learn package not installed.\")\n",
    "    else:\n",
    "        print(\"\\n   Skipping UMAP visualization: Differential profiles empty or not calculated.\")\n",
    "\n",
    "    # --- Combined Co-expression Matrix Plot (Use ordered_channels) ---\n",
    "    print(\"\\n   Generating combined scaled-pixel/avg-comm co-expression matrix...\")\n",
    "    if not scaled_community_profiles.empty:\n",
    "        avg_value_cols_map = {}\n",
    "        try:\n",
    "            for channel in roi_channels:\n",
    "                avg_col_name = f'{channel}_asinh_scaled_avg'\n",
    "                pixel_results_df[avg_col_name] = pixel_results_df['community'].map(scaled_community_profiles[channel]).fillna(0)\n",
    "                avg_value_cols_map[channel] = avg_col_name\n",
    "\n",
    "            coexp_matrix_path = os.path.join(resolution_output_dir, f\"coexpression_matrix_scaled_vs_avg_{roi_string}{res_suffix}.svg\") # Changed extension\n",
    "            plot_coexpression_matrix(\n",
    "                scaled_pixel_expression=scaled_pixel_expression,\n",
    "                pixel_results_df_with_avg=pixel_results_df,\n",
    "                ordered_channels=ordered_channels, # Pass the ordered list here\n",
    "                roi_string=f\"{roi_string} (Res: {resolution_param})\",\n",
    "                config=config,\n",
    "                output_path=coexp_matrix_path\n",
    "            )\n",
    "        except Exception as e:\n",
    "             print(f\"   WARNING: Failed to generate combined co-expression matrix: {e}\")\n",
    "    else:\n",
    "        print(\"   Skipping combined co-expression matrix: Scaled community profiles not available.\")\n",
    "\n",
    "    print(f\"--- Resolution-dependent visualizations finished in {time.time() - start_time_viz:.2f} seconds ---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core analysis function `analyze_roi` defined.\n"
     ]
    }
   ],
   "source": [
    "def analyze_roi(file_idx: int, file_path: str, total_files: int, config: Dict, umap_available_flag: bool):\n",
    "    \"\"\"Orchestrates the analysis pipeline for a single ROI file.\"\"\"\n",
    "    print(f\"\\n================ Analyzing ROI {file_idx+1}/{total_files}: {os.path.basename(file_path)} ================\")\n",
    "    start_roi_time = time.time()\n",
    "\n",
    "    # --- 1. Load & Validate ---\n",
    "    roi_string, roi_output_dir, roi_raw_data, roi_channels = load_and_validate_roi_data(\n",
    "        file_path=file_path,\n",
    "        master_protein_channels=config['data']['master_protein_channels'],\n",
    "        base_output_dir=config['paths']['output_dir'],\n",
    "        metadata_cols=config['data']['metadata_cols']\n",
    "    )\n",
    "    if roi_raw_data is None: return None # Skip file on load error\n",
    "\n",
    "    # --- 2. Calculate Cofactors ---\n",
    "    roi_cofactors = calculate_optimal_cofactors_for_roi(\n",
    "        roi_df=roi_raw_data,\n",
    "        channels_to_process=roi_channels,\n",
    "        default_cofactor=config['data']['default_arcsinh_cofactor'],\n",
    "        output_dir=roi_output_dir,\n",
    "        roi_string=roi_string\n",
    "    )\n",
    "\n",
    "    # --- 3. Preprocess Data ---\n",
    "    scaled_pixel_expression, used_cofactors = apply_per_channel_arcsinh_and_scale(\n",
    "        data_df=roi_raw_data,\n",
    "        channels=roi_channels,\n",
    "        cofactors_map=roi_cofactors,\n",
    "        default_cofactor=config['data']['default_arcsinh_cofactor']\n",
    "    )\n",
    "    if scaled_pixel_expression is None: return None # Skip file on preprocess error\n",
    "\n",
    "    # --- 4. Resolution-Independent Visualizations ---\n",
    "    # This also determines channel order based on pixel correlation\n",
    "    ordered_channels = _generate_resolution_independent_visualizations( # Assumes this helper is defined (or inline it)\n",
    "        roi_raw_data=roi_raw_data,\n",
    "        scaled_pixel_expression=scaled_pixel_expression,\n",
    "        roi_channels=roi_channels,\n",
    "        roi_cofactors=roi_cofactors, # Pass used_cofactors if preferred\n",
    "        roi_output_dir=roi_output_dir,\n",
    "        roi_string=roi_string,\n",
    "        config=config\n",
    "    )\n",
    "    if ordered_channels is None: ordered_channels = roi_channels # Fallback\n",
    "\n",
    "    # --- 5. Loop Through Resolutions ---\n",
    "    resolution_params = config['analysis']['clustering'].get('resolution_params', [0.5])\n",
    "    success_flag = False\n",
    "    for resolution in resolution_params:\n",
    "        pixel_community_df = None; pixel_graph = None; community_partition = None\n",
    "        current_pixel_results_df = None; scaled_community_profiles = None\n",
    "        diff_expr_profiles = None; primary_channel_map = None\n",
    "        try:\n",
    "            print(f\"\\n===== Processing Resolution: {resolution} for ROI: {roi_string} =====\")\n",
    "            res_start_time = time.time()\n",
    "            resolution_str = f\"{resolution:.3f}\".rstrip('0').rstrip('.').replace('.', '_') if isinstance(resolution, float) else str(resolution)\n",
    "            resolution_output_dir = os.path.join(roi_output_dir, f\"resolution_{resolution_str}\")\n",
    "            os.makedirs(resolution_output_dir, exist_ok=True)\n",
    "\n",
    "            # 5a. Cluster Pixels\n",
    "            pixel_coordinates = roi_raw_data[['X', 'Y']].copy().loc[scaled_pixel_expression.index]\n",
    "            pixel_community_df, pixel_graph, community_partition, _ = run_spatial_leiden(\n",
    "                 analysis_df=pixel_coordinates,\n",
    "                 protein_channels=roi_channels,\n",
    "                 scaled_expression_data_for_weights=scaled_pixel_expression.values,\n",
    "                 n_neighbors=config['analysis']['clustering']['n_neighbors'],\n",
    "                 resolution_param=resolution,\n",
    "                 seed=config['analysis']['clustering']['seed'],\n",
    "                 verbose=True\n",
    "            )\n",
    "            if pixel_community_df is None: continue # Skip res if clustering fails\n",
    "\n",
    "            # Create dataframe for this resolution's results\n",
    "            current_pixel_results_df = roi_raw_data[['X', 'Y']].join(scaled_pixel_expression).join(pixel_community_df[['community']])\n",
    "            # Add raw values back if needed for specific analyses (optional)\n",
    "            # for ch in roi_channels: current_pixel_results_df[ch] = roi_raw_data.loc[current_pixel_results_df.index, ch]\n",
    "\n",
    "            # 5b. Analyze Communities\n",
    "            scaled_community_profiles = calculate_and_save_profiles(\n",
    "                 results_df=current_pixel_results_df,\n",
    "                 valid_channels=roi_channels,\n",
    "                 roi_output_dir=resolution_output_dir,\n",
    "                 roi_string=f\"{roi_string}_res_{resolution_str}\"\n",
    "            )\n",
    "            if scaled_community_profiles is None: continue # Skip res if profiles fail\n",
    "\n",
    "            # Optional DiffEx\n",
    "            if config['analysis'].get('differential_expression', {}).get('run_differential_expression', False):\n",
    "                diff_expr_profiles, primary_channel_map = calculate_differential_expression(\n",
    "                    results_df=current_pixel_results_df,\n",
    "                    community_profiles=scaled_community_profiles,\n",
    "                    graph=pixel_graph,\n",
    "                    valid_channels=roi_channels\n",
    "                )\n",
    "                # Save DiffEx results\n",
    "                if diff_expr_profiles is not None:\n",
    "                    diff_expr_profiles.to_csv(os.path.join(resolution_output_dir, f\"community_diff_profiles_{roi_string}_res_{resolution_str}.csv\"))\n",
    "                if primary_channel_map is not None:\n",
    "                     primary_channel_map.to_csv(os.path.join(resolution_output_dir, f\"community_primary_channels_{roi_string}_res_{resolution_str}.csv\"), header=True)\n",
    "\n",
    "            # 5c. Resolution-Dependent Visualizations\n",
    "            _generate_resolution_dependent_visualizations( # Assumes this helper is defined (or inline it)\n",
    "                 pixel_results_df=current_pixel_results_df,\n",
    "                 scaled_pixel_expression=scaled_pixel_expression,\n",
    "                 scaled_community_profiles=scaled_community_profiles,\n",
    "                 diff_expr_profiles=diff_expr_profiles,\n",
    "                 primary_channel_map=primary_channel_map,\n",
    "                 roi_channels=roi_channels,\n",
    "                 ordered_channels=ordered_channels,\n",
    "                 roi_cofactors=roi_cofactors, # Pass used_cofactors if preferred\n",
    "                 resolution_output_dir=resolution_output_dir,\n",
    "                 roi_string=roi_string,\n",
    "                 resolution_param=resolution,\n",
    "                 config=config,\n",
    "                 umap_available_flag=umap_available_flag # Pass the flag\n",
    "            )\n",
    "\n",
    "            # 5d. Save Final Pixel Results for this resolution\n",
    "            final_results_save_path = os.path.join(resolution_output_dir, f\"pixel_analysis_results_final_{roi_string}_res_{resolution_str}.csv\")\n",
    "            save_cols = ['X', 'Y', 'community'] + roi_channels # Example: save coords, community, scaled values\n",
    "            if primary_channel_map is not None:\n",
    "                current_pixel_results_df['primary_channel'] = current_pixel_results_df['community'].map(primary_channel_map).fillna('Unknown')\n",
    "                save_cols.append('primary_channel')\n",
    "            current_pixel_results_df[save_cols].to_csv(final_results_save_path, index=True) # Save relevant columns\n",
    "            print(f\"   Final pixel results saved: {os.path.basename(final_results_save_path)}\")\n",
    "\n",
    "            success_flag = True # Mark success if at least one resolution finishes\n",
    "            print(f\"===== Resolution {resolution} finished in {time.time() - res_start_time:.2f} seconds =====\")\n",
    "\n",
    "        except Exception as resolution_e:\n",
    "             print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "             print(f\"   ERROR during processing resolution {resolution} for ROI {roi_string}: {str(resolution_e)}\")\n",
    "             print(f\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "             import traceback\n",
    "             traceback.print_exc()\n",
    "        finally:\n",
    "            # Clean up memory-intensive objects for this resolution\n",
    "            del pixel_community_df, pixel_graph, community_partition, current_pixel_results_df\n",
    "            del scaled_community_profiles, diff_expr_profiles, primary_channel_map\n",
    "            gc.collect()\n",
    "\n",
    "    if not success_flag:\n",
    "         print(f\"--- WARNING: Analysis failed for all resolutions for ROI: {roi_string} ---\")\n",
    "         return None # Indicate failure for this ROI\n",
    "\n",
    "    print(f\"--- Successfully finished processing ROI: {roi_string} in {time.time() - start_roi_time:.2f} seconds ---\")\n",
    "    return roi_string # Indicate success\n",
    "\n",
    "print(\"Core analysis function `analyze_roi` defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Find Input Files\n",
    "Locate all `.txt` files in the specified data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: No .txt files found in data directory: /Users/noot/Documents/IMC/data/241218_IMC_Alun/\n"
     ]
    }
   ],
   "source": [
    "imc_files = []\n",
    "if config:\n",
    "    data_dir = config['paths']['data_dir']\n",
    "    try:\n",
    "        imc_files = sorted(glob.glob(os.path.join(data_dir, \"*.txt\"))) # Sort for consistency\n",
    "        if not imc_files:\n",
    "            print(f\"ERROR: No .txt files found in data directory: {data_dir}\")\n",
    "        else:\n",
    "            print(f\"\\nFound {len(imc_files)} IMC data files to process:\")\n",
    "            # Print first few files\n",
    "            for f in imc_files[:min(5, len(imc_files))]: print(f\"  - {os.path.basename(f)}\")\n",
    "            if len(imc_files) > 5: print(\"  ...\")\n",
    "    except Exception as e:\n",
    "         print(f\"ERROR finding input files in {data_dir}: {e}\")\n",
    "         imc_files = [] # Ensure it's empty on error\n",
    "else:\n",
    "    print(\"Skipping file search due to missing configuration.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Setup Parallel Processing\n",
    "Determine the number of CPU cores to use based on the configuration (`processing: parallel_jobs`). `-1` uses all cores, `-2` uses all but one, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configured to use 15 cores for parallel processing.\n"
     ]
    }
   ],
   "source": [
    "n_jobs = 1\n",
    "if config:\n",
    "    try:\n",
    "        parallel_jobs_config = config['processing']['parallel_jobs']\n",
    "        cpu_count = multiprocessing.cpu_count()\n",
    "        if isinstance(parallel_jobs_config, int):\n",
    "            if parallel_jobs_config == -1:\n",
    "                n_jobs = cpu_count\n",
    "            elif parallel_jobs_config <= -2:\n",
    "                n_jobs = max(1, cpu_count + parallel_jobs_config + 1)\n",
    "            elif parallel_jobs_config > 0:\n",
    "                n_jobs = min(parallel_jobs_config, cpu_count)\n",
    "            else: # 0 or invalid\n",
    "                n_jobs = 1\n",
    "        else: n_jobs = 1 # Default for invalid type\n",
    "        print(f\"\\nConfigured to use {n_jobs} cores for parallel processing.\")\n",
    "    except KeyError:\n",
    "         print(\"\\nWarning: 'parallel_jobs' not found in config. Defaulting to 1 core.\")\n",
    "         n_jobs = 1\n",
    "    except Exception as e:\n",
    "         print(f\"\\nWarning: Error determining parallel jobs: {e}. Defaulting to 1 core.\")\n",
    "         n_jobs = 1\n",
    "else:\n",
    "    print(\"Skipping parallel setup due to missing configuration.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run analysis over all ROIs\n",
    "\n",
    "Execute the `analyze_roi` function for each input file using `joblib.Parallel`.\n",
    "\n",
    "**Note:** This cell may take a significant amount of time depending on the number of ROIs, data size, number of resolutions, and number of cores used. **Ensure `analyze_roi` is defined in an imported `.py` module if `n_jobs > 1`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting parallel execution (9 jobs)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=9)]: Using backend LokyBackend with 9 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Analyzing ROI 5/25: IMC_241218_Alun_ROI_D1_M2_02_13.txt ================\n",
      "--- Loading and Validating: IMC_241218_Alun_ROI_D1_M2_02_13.txt ---\n",
      "ROI Identifier: ROI_D1_M2_02_13\n",
      "Loading data...\n",
      "\n",
      "================ Analyzing ROI 2/25: IMC_241218_Alun_ROI_D1_M1_02_10.txt ================\n",
      "--- Loading and Validating: IMC_241218_Alun_ROI_D1_M1_02_10.txt ---\n",
      "ROI Identifier: ROI_D1_M1_02_10\n",
      "Loading data...\n",
      "\n",
      "================ Analyzing ROI 4/25: IMC_241218_Alun_ROI_D1_M2_01_12.txt ================\n",
      "--- Loading and Validating: IMC_241218_Alun_ROI_D1_M2_01_12.txt ---\n",
      "ROI Identifier: ROI_D1_M2_01_12\n",
      "Loading data...\n",
      "\n",
      "================ Analyzing ROI 7/25: IMC_241218_Alun_ROI_D3_M1_01_15.txt ================\n",
      "--- Loading and Validating: IMC_241218_Alun_ROI_D3_M1_01_15.txt ---\n",
      "ROI Identifier: ROI_D3_M1_01_15\n",
      "Loading data...\n",
      "\n",
      "================ Analyzing ROI 9/25: IMC_241218_Alun_ROI_D3_M1_03_17.txt ================\n",
      "--- Loading and Validating: IMC_241218_Alun_ROI_D3_M1_03_17.txt ---\n",
      "ROI Identifier: ROI_D3_M1_03_17\n",
      "Loading data...\n",
      "\n",
      "================ Analyzing ROI 1/25: IMC_241218_Alun_ROI_D1_M1_01_9.txt ================\n",
      "--- Loading and Validating: IMC_241218_Alun_ROI_D1_M1_01_9.txt ---\n",
      "ROI Identifier: ROI_D1_M1_01_9\n",
      "Loading data...\n",
      "\n",
      "================ Analyzing ROI 3/25: IMC_241218_Alun_ROI_D1_M1_03_11.txt ================\n",
      "--- Loading and Validating: IMC_241218_Alun_ROI_D1_M1_03_11.txt ---\n",
      "ROI Identifier: ROI_D1_M1_03_11\n",
      "Loading data...\n",
      "\n",
      "================ Analyzing ROI 8/25: IMC_241218_Alun_ROI_D3_M1_02_16.txt ================\n",
      "--- Loading and Validating: IMC_241218_Alun_ROI_D3_M1_02_16.txt ---\n",
      "ROI Identifier: ROI_D3_M1_02_16\n",
      "Loading data...\n",
      "\n",
      "================ Analyzing ROI 6/25: IMC_241218_Alun_ROI_D1_M2_03_14.txt ================\n",
      "--- Loading and Validating: IMC_241218_Alun_ROI_D1_M2_03_14.txt ---\n",
      "ROI Identifier: ROI_D1_M2_03_14\n",
      "Loading data...\n",
      "Loaded data with shape: (250000, 21)\n",
      "Using 9 channels for analysis.\n",
      "\n",
      "Calculating optimal Arcsinh cofactors for ROI...\n",
      "Loaded data with shape: (250000, 21)\n",
      "Using 9 channels for analysis.\n",
      "Loaded data with shape: (250000, 21)\n",
      "Using 9 channels for analysis.\n",
      "\n",
      "Calculating optimal Arcsinh cofactors for ROI...\n",
      "\n",
      "Calculating optimal Arcsinh cofactors for ROI...\n",
      "Loaded data with shape: (250000, 21)\n",
      "Using 9 channels for analysis.\n",
      "Loaded data with shape: (250000, 21)\n",
      "Using 9 channels for analysis.\n",
      "\n",
      "Calculating optimal Arcsinh cofactors for ROI...\n",
      "\n",
      "Calculating optimal Arcsinh cofactors for ROI...\n",
      "Loaded data with shape: (250000, 21)\n",
      "Using 9 channels for analysis.\n",
      "\n",
      "Calculating optimal Arcsinh cofactors for ROI...\n",
      "Loaded data with shape: (250000, 21)\n",
      "Using 9 channels for analysis.\n",
      "\n",
      "Calculating optimal Arcsinh cofactors for ROI...\n",
      "Loaded data with shape: (250000, 21)\n",
      "Using 9 channels for analysis.\n",
      "\n",
      "Calculating optimal Arcsinh cofactors for ROI...\n",
      "Loaded data with shape: (250000, 21)\n",
      "Using 9 channels for analysis.\n",
      "\n",
      "Calculating optimal Arcsinh cofactors for ROI...\n",
      "--- Cofactor calculation finished in 0.77 seconds ---\n",
      "   Optimal cofactors saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M1_03_11/optimal_cofactors_ROI_D1_M1_03_11.json\n",
      "\n",
      "--- Applying Per-Channel Arcsinh (using optimal cofactors) and Scaling ---\n",
      "   Applying arcsinh transformation with specific cofactors...\n",
      "--- Cofactor calculation finished in 0.90 seconds ---\n",
      "   Optimal cofactors saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M1_02_10/optimal_cofactors_ROI_D1_M1_02_10.json\n",
      "\n",
      "--- Applying Per-Channel Arcsinh (using optimal cofactors) and Scaling ---\n",
      "   Applying MinMaxScaler to transformed data...\n",
      "   Applying arcsinh transformation with specific cofactors...\n",
      "--- Transformation and scaling finished in 0.06 seconds ---\n",
      "\n",
      "Generating resolution-independent visualizations...\n",
      "   Generating pixel-level correlation clustermap...\n",
      "   Applying MinMaxScaler to transformed data...\n",
      "--- Transformation and scaling finished in 0.05 seconds ---\n",
      "\n",
      "Generating resolution-independent visualizations...\n",
      "   Generating pixel-level correlation clustermap...\n",
      "   Generating clustermap: pixel_channel_correlation_heatmap_spearman_ROI_D1_M1_03_11.svg\n",
      "   Generating clustermap: pixel_channel_correlation_heatmap_spearman_ROI_D1_M1_02_10.svg\n",
      "--- Cofactor calculation finished in 1.05 seconds ---\n",
      "   Optimal cofactors saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M2_03_14/optimal_cofactors_ROI_D1_M2_03_14.json\n",
      "\n",
      "--- Applying Per-Channel Arcsinh (using optimal cofactors) and Scaling ---\n",
      "   Applying arcsinh transformation with specific cofactors...\n",
      "   Applying MinMaxScaler to transformed data...\n",
      "--- Transformation and scaling finished in 0.04 seconds ---\n",
      "\n",
      "Generating resolution-independent visualizations...\n",
      "   Generating pixel-level correlation clustermap...\n",
      "--- Cofactor calculation finished in 1.30 seconds ---\n",
      "   Optimal cofactors saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M2_02_13/optimal_cofactors_ROI_D1_M2_02_13.json\n",
      "\n",
      "--- Applying Per-Channel Arcsinh (using optimal cofactors) and Scaling ---\n",
      "   Applying arcsinh transformation with specific cofactors...\n",
      "   Applying MinMaxScaler to transformed data...\n",
      "   Generating clustermap: pixel_channel_correlation_heatmap_spearman_ROI_D1_M2_03_14.svg\n",
      "--- Transformation and scaling finished in 0.05 seconds ---\n",
      "\n",
      "Generating resolution-independent visualizations...\n",
      "   Generating pixel-level correlation clustermap...\n",
      "--- Cofactor calculation finished in 1.31 seconds ---\n",
      "   Optimal cofactors saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M1_01_9/optimal_cofactors_ROI_D1_M1_01_9.json\n",
      "\n",
      "--- Applying Per-Channel Arcsinh (using optimal cofactors) and Scaling ---\n",
      "   Applying arcsinh transformation with specific cofactors...\n",
      "   Applying MinMaxScaler to transformed data...\n",
      "--- Transformation and scaling finished in 0.05 seconds ---\n",
      "\n",
      "Generating resolution-independent visualizations...\n",
      "   Generating pixel-level correlation clustermap...\n",
      "   Generating clustermap: pixel_channel_correlation_heatmap_spearman_ROI_D1_M2_02_13.svg\n",
      "--- Cofactor calculation finished in 1.52 seconds ---\n",
      "   Optimal cofactors saved to: /Users/noot/Documents/IMC/output_plots/ROI_D3_M1_01_15/optimal_cofactors_ROI_D3_M1_01_15.json\n",
      "\n",
      "--- Applying Per-Channel Arcsinh (using optimal cofactors) and Scaling ---\n",
      "   Generating clustermap: pixel_channel_correlation_heatmap_spearman_ROI_D1_M1_01_9.svg\n",
      "   Applying arcsinh transformation with specific cofactors...\n",
      "   Applying MinMaxScaler to transformed data...\n",
      "--- Transformation and scaling finished in 0.06 seconds ---\n",
      "   Determined channel order from clustermap: ['Ly6G(Pr141Di)', 'CD140a(Nd148Di)', 'CD140b(Eu151Di)', 'CD206(Tm169Di)', 'CD31(Sm154Di)', 'CD34(Er166Di)', 'CD45(Y89Di)', 'CD11b(Nd143Di)', 'CD44(Yb171Di)']\n",
      "--- Cofactor calculation finished in 1.57 seconds ---\n",
      "\n",
      "Generating resolution-independent visualizations...\n",
      "   Generating pixel-level correlation clustermap...\n",
      "   Optimal cofactors saved to: /Users/noot/Documents/IMC/output_plots/ROI_D3_M1_03_17/optimal_cofactors_ROI_D3_M1_03_17.json\n",
      "\n",
      "--- Applying Per-Channel Arcsinh (using optimal cofactors) and Scaling ---\n",
      "   Determined channel order from clustermap: ['Ly6G(Pr141Di)', 'CD45(Y89Di)', 'CD11b(Nd143Di)', 'CD44(Yb171Di)', 'CD206(Tm169Di)', 'CD31(Sm154Di)', 'CD34(Er166Di)', 'CD140a(Nd148Di)', 'CD140b(Eu151Di)']\n",
      "   Applying arcsinh transformation with specific cofactors...\n",
      "   Applying MinMaxScaler to transformed data...\n",
      "--- Cofactor calculation finished in 1.68 seconds ---\n",
      "   Optimal cofactors saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M2_01_12/optimal_cofactors_ROI_D1_M2_01_12.json\n",
      "\n",
      "--- Applying Per-Channel Arcsinh (using optimal cofactors) and Scaling ---\n",
      "--- Transformation and scaling finished in 0.06 seconds ---\n",
      "\n",
      "Generating resolution-independent visualizations...\n",
      "   Generating pixel-level correlation clustermap...\n",
      "   Applying arcsinh transformation with specific cofactors...\n",
      "   Applying MinMaxScaler to transformed data...\n",
      "--- Transformation and scaling finished in 0.06 seconds ---\n",
      "\n",
      "Generating resolution-independent visualizations...\n",
      "   Generating pixel-level correlation clustermap...\n",
      "   Generating clustermap: pixel_channel_correlation_heatmap_spearman_ROI_D3_M1_01_15.svg\n",
      "   Determined channel order from clustermap: ['Ly6G(Pr141Di)', 'CD206(Tm169Di)', 'CD45(Y89Di)', 'CD140a(Nd148Di)', 'CD31(Sm154Di)', 'CD34(Er166Di)', 'CD11b(Nd143Di)', 'CD140b(Eu151Di)', 'CD44(Yb171Di)']\n",
      "   Correlation clustermap saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M1_02_10/pixel_channel_correlation_heatmap_spearman_ROI_D1_M1_02_10.svg\n",
      "   Generating Raw vs Scaled Spatial Expression Matrix...\n",
      "   Generating Raw vs. Scaled Spatial Comparison (GridSpec): spatial_raw_vs_scaled_matrix_ROI_D1_M1_02_10.svg\n",
      "--- Cofactor calculation finished in 1.67 seconds ---\n",
      "   Optimal cofactors saved to: /Users/noot/Documents/IMC/output_plots/ROI_D3_M1_02_16/optimal_cofactors_ROI_D3_M1_02_16.json\n",
      "\n",
      "--- Applying Per-Channel Arcsinh (using optimal cofactors) and Scaling ---\n",
      "   Correlation clustermap saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M1_03_11/pixel_channel_correlation_heatmap_spearman_ROI_D1_M1_03_11.svg\n",
      "   Generating Raw vs Scaled Spatial Expression Matrix...\n",
      "   Generating Raw vs. Scaled Spatial Comparison (GridSpec): spatial_raw_vs_scaled_matrix_ROI_D1_M1_03_11.svg\n",
      "   Applying arcsinh transformation with specific cofactors...\n",
      "   Generating clustermap: pixel_channel_correlation_heatmap_spearman_ROI_D3_M1_03_17.svg\n",
      "   Applying MinMaxScaler to transformed data...\n",
      "--- Transformation and scaling finished in 0.07 seconds ---\n",
      "\n",
      "Generating resolution-independent visualizations...\n",
      "   Generating pixel-level correlation clustermap...\n",
      "   Generating clustermap: pixel_channel_correlation_heatmap_spearman_ROI_D1_M2_01_12.svg\n",
      "   Correlation clustermap saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M2_03_14/pixel_channel_correlation_heatmap_spearman_ROI_D1_M2_03_14.svg\n",
      "   Generating Raw vs Scaled Spatial Expression Matrix...\n",
      "   Generating Raw vs. Scaled Spatial Comparison (GridSpec): spatial_raw_vs_scaled_matrix_ROI_D1_M2_03_14.svg\n",
      "   Determined channel order from clustermap: ['Ly6G(Pr141Di)', 'CD45(Y89Di)', 'CD11b(Nd143Di)', 'CD44(Yb171Di)', 'CD206(Tm169Di)', 'CD140a(Nd148Di)', 'CD140b(Eu151Di)', 'CD31(Sm154Di)', 'CD34(Er166Di)']\n",
      "   Generating clustermap: pixel_channel_correlation_heatmap_spearman_ROI_D3_M1_02_16.svg\n",
      "   Determined channel order from clustermap: ['CD140a(Nd148Di)', 'CD140b(Eu151Di)', 'CD44(Yb171Di)', 'CD31(Sm154Di)', 'CD34(Er166Di)', 'Ly6G(Pr141Di)', 'CD206(Tm169Di)', 'CD45(Y89Di)', 'CD11b(Nd143Di)']\n",
      "   Correlation clustermap saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M2_02_13/pixel_channel_correlation_heatmap_spearman_ROI_D1_M2_02_13.svg\n",
      "   Generating Raw vs Scaled Spatial Expression Matrix...\n",
      "   Generating Raw vs. Scaled Spatial Comparison (GridSpec): spatial_raw_vs_scaled_matrix_ROI_D1_M2_02_13.svg\n",
      "   Determined channel order from clustermap: ['Ly6G(Pr141Di)', 'CD31(Sm154Di)', 'CD34(Er166Di)', 'CD45(Y89Di)', 'CD140a(Nd148Di)', 'CD140b(Eu151Di)', 'CD44(Yb171Di)', 'CD11b(Nd143Di)', 'CD206(Tm169Di)']\n",
      "   Correlation clustermap saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M1_01_9/pixel_channel_correlation_heatmap_spearman_ROI_D1_M1_01_9.svg\n",
      "   Generating Raw vs Scaled Spatial Expression Matrix...\n",
      "   Generating Raw vs. Scaled Spatial Comparison (GridSpec): spatial_raw_vs_scaled_matrix_ROI_D1_M1_01_9.svg\n",
      "   Determined channel order from clustermap: ['Ly6G(Pr141Di)', 'CD206(Tm169Di)', 'CD140a(Nd148Di)', 'CD31(Sm154Di)', 'CD34(Er166Di)', 'CD45(Y89Di)', 'CD140b(Eu151Di)', 'CD11b(Nd143Di)', 'CD44(Yb171Di)']\n",
      "   Determined channel order from clustermap: ['CD31(Sm154Di)', 'CD34(Er166Di)', 'CD44(Yb171Di)', 'CD140a(Nd148Di)', 'CD140b(Eu151Di)', 'Ly6G(Pr141Di)', 'CD206(Tm169Di)', 'CD45(Y89Di)', 'CD11b(Nd143Di)']\n",
      "   Correlation clustermap saved to: /Users/noot/Documents/IMC/output_plots/ROI_D3_M1_01_15/pixel_channel_correlation_heatmap_spearman_ROI_D3_M1_01_15.svg\n",
      "   Generating Raw vs Scaled Spatial Expression Matrix...\n",
      "   Generating Raw vs. Scaled Spatial Comparison (GridSpec): spatial_raw_vs_scaled_matrix_ROI_D3_M1_01_15.svg\n",
      "   Determined channel order from clustermap: ['Ly6G(Pr141Di)', 'CD31(Sm154Di)', 'CD34(Er166Di)', 'CD45(Y89Di)', 'CD140a(Nd148Di)', 'CD140b(Eu151Di)', 'CD44(Yb171Di)', 'CD11b(Nd143Di)', 'CD206(Tm169Di)']\n",
      "   Correlation clustermap saved to: /Users/noot/Documents/IMC/output_plots/ROI_D3_M1_03_17/pixel_channel_correlation_heatmap_spearman_ROI_D3_M1_03_17.svg\n",
      "   Generating Raw vs Scaled Spatial Expression Matrix...\n",
      "   Generating Raw vs. Scaled Spatial Comparison (GridSpec): spatial_raw_vs_scaled_matrix_ROI_D3_M1_03_17.svg\n",
      "   Correlation clustermap saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M2_01_12/pixel_channel_correlation_heatmap_spearman_ROI_D1_M2_01_12.svg\n",
      "   Generating Raw vs Scaled Spatial Expression Matrix...\n",
      "   Generating Raw vs. Scaled Spatial Comparison (GridSpec): spatial_raw_vs_scaled_matrix_ROI_D1_M2_01_12.svg\n",
      "   Correlation clustermap saved to: /Users/noot/Documents/IMC/output_plots/ROI_D3_M1_02_16/pixel_channel_correlation_heatmap_spearman_ROI_D3_M1_02_16.svg\n",
      "   Generating Raw vs Scaled Spatial Expression Matrix...\n",
      "   Generating Raw vs. Scaled Spatial Comparison (GridSpec): spatial_raw_vs_scaled_matrix_ROI_D3_M1_02_16.svg\n",
      "   Raw vs. Scaled Spatial Comparison (GridSpec) saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M1_03_11/spatial_raw_vs_scaled_matrix_ROI_D1_M1_03_11.svg\n",
      "--- Resolution-independent visualizations finished in 64.96 seconds ---\n",
      "\n",
      "===== Processing Resolution: 0.3 for ROI: ROI_D1_M1_03_11 =====\n",
      "--- Running Spatial Leiden (k=65, res=0.3) on 250000 pixels ---\n",
      "\n",
      "1. Validating pre-scaled expression data...\n",
      "\n",
      "2. Building spatial k-NN graph (k=65)...\n",
      "   Raw vs. Scaled Spatial Comparison (GridSpec) saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M1_02_10/spatial_raw_vs_scaled_matrix_ROI_D1_M1_02_10.svg\n",
      "--- Resolution-independent visualizations finished in 65.21 seconds ---\n",
      "\n",
      "===== Processing Resolution: 0.3 for ROI: ROI_D1_M1_02_10 =====\n",
      "--- Running Spatial Leiden (k=65, res=0.3) on 250000 pixels ---\n",
      "\n",
      "1. Validating pre-scaled expression data...\n",
      "\n",
      "2. Building spatial k-NN graph (k=65)...\n",
      "   Raw vs. Scaled Spatial Comparison (GridSpec) saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M2_02_13/spatial_raw_vs_scaled_matrix_ROI_D1_M2_02_13.svg\n",
      "--- Resolution-independent visualizations finished in 64.89 seconds ---\n",
      "\n",
      "===== Processing Resolution: 0.3 for ROI: ROI_D1_M2_02_13 =====\n",
      "--- Running Spatial Leiden (k=65, res=0.3) on 250000 pixels ---\n",
      "\n",
      "1. Validating pre-scaled expression data...\n",
      "\n",
      "2. Building spatial k-NN graph (k=65)...\n",
      "   Raw vs. Scaled Spatial Comparison (GridSpec) saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M2_01_12/spatial_raw_vs_scaled_matrix_ROI_D1_M2_01_12.svg\n",
      "--- Resolution-independent visualizations finished in 64.56 seconds ---\n",
      "\n",
      "===== Processing Resolution: 0.3 for ROI: ROI_D1_M2_01_12 =====\n",
      "--- Running Spatial Leiden (k=65, res=0.3) on 250000 pixels ---\n",
      "\n",
      "1. Validating pre-scaled expression data...\n",
      "\n",
      "2. Building spatial k-NN graph (k=65)...\n",
      "   Raw vs. Scaled Spatial Comparison (GridSpec) saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M2_03_14/spatial_raw_vs_scaled_matrix_ROI_D1_M2_03_14.svg\n",
      "--- Resolution-independent visualizations finished in 65.15 seconds ---\n",
      "\n",
      "===== Processing Resolution: 0.3 for ROI: ROI_D1_M2_03_14 =====\n",
      "--- Running Spatial Leiden (k=65, res=0.3) on 250000 pixels ---\n",
      "\n",
      "1. Validating pre-scaled expression data...\n",
      "\n",
      "2. Building spatial k-NN graph (k=65)...\n",
      "   Raw vs. Scaled Spatial Comparison (GridSpec) saved to: /Users/noot/Documents/IMC/output_plots/ROI_D1_M1_01_9/spatial_raw_vs_scaled_matrix_ROI_D1_M1_01_9.svg\n",
      "--- Resolution-independent visualizations finished in 65.00 seconds ---\n",
      "\n",
      "===== Processing Resolution: 0.3 for ROI: ROI_D1_M1_01_9 =====\n",
      "--- Running Spatial Leiden (k=65, res=0.3) on 250000 pixels ---\n",
      "\n",
      "1. Validating pre-scaled expression data...\n",
      "\n",
      "2. Building spatial k-NN graph (k=65)...\n",
      "   Raw vs. Scaled Spatial Comparison (GridSpec) saved to: /Users/noot/Documents/IMC/output_plots/ROI_D3_M1_01_15/spatial_raw_vs_scaled_matrix_ROI_D3_M1_01_15.svg\n",
      "--- Resolution-independent visualizations finished in 64.85 seconds ---\n",
      "\n",
      "===== Processing Resolution: 0.3 for ROI: ROI_D3_M1_01_15 =====\n",
      "--- Running Spatial Leiden (k=65, res=0.3) on 250000 pixels ---\n",
      "\n",
      "1. Validating pre-scaled expression data...\n",
      "\n",
      "2. Building spatial k-NN graph (k=65)...\n",
      "   Raw vs. Scaled Spatial Comparison (GridSpec) saved to: /Users/noot/Documents/IMC/output_plots/ROI_D3_M1_02_16/spatial_raw_vs_scaled_matrix_ROI_D3_M1_02_16.svg\n",
      "--- Resolution-independent visualizations finished in 65.01 seconds ---\n",
      "\n",
      "===== Processing Resolution: 0.3 for ROI: ROI_D3_M1_02_16 =====\n",
      "--- Running Spatial Leiden (k=65, res=0.3) on 250000 pixels ---\n",
      "\n",
      "1. Validating pre-scaled expression data...\n",
      "\n",
      "2. Building spatial k-NN graph (k=65)...\n",
      "   Raw vs. Scaled Spatial Comparison (GridSpec) saved to: /Users/noot/Documents/IMC/output_plots/ROI_D3_M1_03_17/spatial_raw_vs_scaled_matrix_ROI_D3_M1_03_17.svg\n",
      "--- Resolution-independent visualizations finished in 65.44 seconds ---\n",
      "\n",
      "===== Processing Resolution: 0.3 for ROI: ROI_D3_M1_03_17 =====\n",
      "--- Running Spatial Leiden (k=65, res=0.3) on 250000 pixels ---\n",
      "\n",
      "1. Validating pre-scaled expression data...\n",
      "\n",
      "2. Building spatial k-NN graph (k=65)...\n",
      "   Spatial k-NN took 1.89 seconds.\n",
      "\n",
      "3. Calculating edge weights based on expression similarity...\n",
      "   Spatial k-NN took 1.90 seconds.\n",
      "\n",
      "3. Calculating edge weights based on expression similarity...\n",
      "   Spatial k-NN took 1.94 seconds.\n",
      "\n",
      "3. Calculating edge weights based on expression similarity...\n",
      "   Spatial k-NN took 1.88 seconds.\n",
      "\n",
      "3. Calculating edge weights based on expression similarity...\n",
      "   Spatial k-NN took 1.95 seconds.\n",
      "\n",
      "3. Calculating edge weights based on expression similarity...\n",
      "   Spatial k-NN took 1.91 seconds.\n",
      "\n",
      "3. Calculating edge weights based on expression similarity...\n",
      "   Spatial k-NN took 1.92 seconds.\n",
      "\n",
      "3. Calculating edge weights based on expression similarity...\n",
      "   Spatial k-NN took 1.88 seconds.\n",
      "\n",
      "3. Calculating edge weights based on expression similarity...\n",
      "   Spatial k-NN took 1.83 seconds.\n",
      "\n",
      "3. Calculating edge weights based on expression similarity...\n",
      "   Calculated 8037058 edge weights.\n",
      "   Weight calculation took 18.98 seconds.\n",
      "\n",
      "4. Constructing igraph graph...\n",
      "   Calculated 8037058 edge weights.\n",
      "   Weight calculation took 19.00 seconds.\n",
      "\n",
      "4. Constructing igraph graph...\n",
      "   Calculated 8037058 edge weights.\n",
      "   Weight calculation took 19.09 seconds.\n",
      "\n",
      "4. Constructing igraph graph...\n",
      "   Calculated 8037058 edge weights.\n",
      "   Weight calculation took 18.94 seconds.\n",
      "\n",
      "4. Constructing igraph graph...\n",
      "   Calculated 8037058 edge weights.\n",
      "   Weight calculation took 19.07 seconds.\n",
      "\n",
      "4. Constructing igraph graph...\n",
      "   Calculated 8037058 edge weights.\n",
      "   Weight calculation took 19.14 seconds.\n",
      "\n",
      "4. Constructing igraph graph...\n",
      "   Calculated 8037058 edge weights.\n",
      "   Weight calculation took 19.44 seconds.\n",
      "\n",
      "4. Constructing igraph graph...\n",
      "   Calculated 8037058 edge weights.\n",
      "   Weight calculation took 18.96 seconds.\n",
      "\n",
      "4. Constructing igraph graph...\n",
      "   Calculated 8037058 edge weights.\n",
      "   Weight calculation took 19.47 seconds.\n",
      "\n",
      "4. Constructing igraph graph...\n",
      "   Graph summary: IGRAPH U-W- 250000 8037058 -- \n",
      "+ attr: weight (e)\n",
      "   Graph construction took 3.91 seconds.\n",
      "\n",
      "5. Running Leiden Algorithm (Resolution=0.3)...\n",
      "   Graph summary: IGRAPH U-W- 250000 8037058 -- \n",
      "+ attr: weight (e)\n",
      "   Graph construction took 5.30 seconds.\n",
      "\n",
      "5. Running Leiden Algorithm (Resolution=0.3)...\n",
      "   Graph summary: IGRAPH U-W- 250000 8037058 -- \n",
      "+ attr: weight (e)\n",
      "   Graph construction took 5.78 seconds.\n",
      "\n",
      "5. Running Leiden Algorithm (Resolution=0.3)...\n",
      "   Graph summary: IGRAPH U-W- 250000 8037058 -- \n",
      "+ attr: weight (e)\n",
      "   Graph construction took 6.44 seconds.\n",
      "\n",
      "5. Running Leiden Algorithm (Resolution=0.3)...\n",
      "   Graph summary: IGRAPH U-W- 250000 8037058 -- \n",
      "+ attr: weight (e)\n",
      "   Graph construction took 7.83 seconds.\n",
      "\n",
      "5. Running Leiden Algorithm (Resolution=0.3)...\n",
      "   Graph summary: IGRAPH U-W- 250000 8037058 -- \n",
      "+ attr: weight (e)\n",
      "   Graph construction took 7.99 seconds.\n",
      "\n",
      "5. Running Leiden Algorithm (Resolution=0.3)...\n",
      "   Graph summary: IGRAPH U-W- 250000 8037058 -- \n",
      "+ attr: weight (e)\n",
      "   Graph construction took 8.11 seconds.\n",
      "\n",
      "5. Running Leiden Algorithm (Resolution=0.3)...\n",
      "   Graph summary: IGRAPH U-W- 250000 8037058 -- \n",
      "+ attr: weight (e)\n",
      "   Graph construction took 8.19 seconds.\n",
      "\n",
      "5. Running Leiden Algorithm (Resolution=0.3)...\n",
      "   Graph summary: IGRAPH U-W- 250000 8037058 -- \n",
      "+ attr: weight (e)\n",
      "   Graph construction took 8.83 seconds.\n",
      "\n",
      "5. Running Leiden Algorithm (Resolution=0.3)...\n"
     ]
    }
   ],
   "source": [
    "analysis_results = []\n",
    "if config and imc_files:\n",
    "    start_parallel_time = time.time()\n",
    "    print(f\"\\nStarting parallel execution ({n_jobs} jobs)...\")\n",
    "    # Run the parallel processing\n",
    "    analysis_results = Parallel(n_jobs=n_jobs, verbose=10)(\n",
    "        delayed(analyze_roi)(\n",
    "            i,\n",
    "            file_path,\n",
    "            len(imc_files),\n",
    "            config,\n",
    "            umap_available # Pass umap flag\n",
    "            )\n",
    "        for i, file_path in enumerate(imc_files)\n",
    "    )\n",
    "\n",
    "    print(f\"\\n--- Parallel processing finished in {time.time() - start_parallel_time:.2f} seconds ---\")\n",
    "else:\n",
    "    print(\"\\nSkipping parallel execution: Missing configuration or input files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summarize Results\n",
    "Count the number of successfully processed ROIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if analysis_results:\n",
    "    successful_rois = [r for r in analysis_results if r is not None]\n",
    "    failed_rois_count = len(analysis_results) - len(successful_rois)\n",
    "\n",
    "    print(f\"\\n--- Pipeline Summary ---\")\n",
    "    print(f\"Total ROIs processed: {len(analysis_results)}\")\n",
    "    print(f\"Successfully completed: {len(successful_rois)}\")\n",
    "    if failed_rois_count > 0:\n",
    "        print(f\"Failed or partially failed: {failed_rois_count} (Check logs above for details).\")\n",
    "else:\n",
    "    print(\"\\nNo analysis was performed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "The per-ROI processing is complete. The necessary outputs (community profiles, pixel results) have been saved to the output directory structure.\n",
    "\n",
    "Proceed to the **Experiment-Level Analysis Notebook** (`run_experiment_analysis.ipynb`) to aggregate these results and perform comparative analyses across conditions/timepoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/noot/IMC/data/241218_IMC_Alun\n",
      "\n",
      "Files in current directory:\n",
      "  - IMC_241218_Alun_ROI_Sam2_03_8.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D3_M1_03_17.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D1_M2_02_13.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D3_M2_03_20.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D3_M2_01_18.txt (File)\n",
      "  - IMC_241218_Alun_ROI_Sam1_01_2.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D1_M1_01_9.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D7_M2_02_25.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D1_M2_01_12.txt (File)\n",
      "  - IMC_241218_Alun.mcd (File)\n",
      "  - IMC_241218_Alun_ROI_D3_M1_02_16.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D1_M1_03_11.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D7_M1_03_23.txt (File)\n",
      "  - IMC_241218_Alun_ROI_Test01_1.txt (File)\n",
      "  - IMC_241218_Alun_ROI_Sam2_02_7.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D7_M1_02_22.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D7_M1_01_21.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D3_M2_02_19.txt (File)\n",
      "  - Logbook_PorpigliaLab_IMC_Alun_241218.log (File)\n",
      "  - IMC_241218_Alun_kidney.jpg (File)\n",
      "  - IMC_241218_Alun_ROI_Sam2_01_6.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D1_M1_02_10.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D1_M2_03_14.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D7_M2_01_24.txt (File)\n",
      "  - IMC_241218_Alun_ROI_Sam1_02_3.txt (File)\n",
      "  - IMC_241218_Alun_ROI_Sam1_03_4.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D7_M2_03_26.txt (File)\n",
      "  - IMC_241218_Alun_ROI_D3_M1_01_15.txt (File)\n",
      "\n",
      "Directory structure:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "walk() got an unexpected keyword argument 'maxdepth'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Show directory structure (limited depth)\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDirectory structure:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m root, dirs, files \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwalk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtopdown\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxdepth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m     19\u001b[39m     level = root.replace(current_dir, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m).count(os.sep)\n\u001b[32m     20\u001b[39m     indent = \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m * \u001b[32m4\u001b[39m * level\n",
      "\u001b[31mTypeError\u001b[39m: walk() got an unexpected keyword argument 'maxdepth'"
     ]
    }
   ],
   "source": [
    "# Explore current directory\n",
    "import os\n",
    "\n",
    "# Get current working directory\n",
    "current_dir = f\"{os.getcwd()}/data/241218_IMC_Alun\"\n",
    "print(f\"Current working directory: {current_dir}\")\n",
    "\n",
    "# List files in the current directory\n",
    "print(\"\\nFiles in current directory:\")\n",
    "for item in os.listdir(current_dir):\n",
    "    if os.path.isfile(os.path.join(current_dir, item)):\n",
    "        print(f\"  - {item} (File)\")\n",
    "    elif os.path.isdir(os.path.join(current_dir, item)):\n",
    "        print(f\"  - {item} (Directory)\")\n",
    "        \n",
    "# Show directory structure (limited depth)\n",
    "print(\"\\nDirectory structure:\")\n",
    "for root, dirs, files in os.walk(current_dir, topdown=True, maxdepth=2):\n",
    "    level = root.replace(current_dir, '').count(os.sep)\n",
    "    indent = ' ' * 4 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    sub_indent = ' ' * 4 * (level + 1)\n",
    "    for f in files[:5]:  # Limit to first 5 files\n",
    "        print(f\"{sub_indent}{f}\")\n",
    "    if len(files) > 5:\n",
    "        print(f\"{sub_indent}... ({len(files)-5} more files)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
