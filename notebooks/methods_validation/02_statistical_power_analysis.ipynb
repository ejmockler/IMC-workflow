{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Power Analysis for n=2 Study\n",
    "\n",
    "**Goal**: Quantify what biological effects are detectable with n=2 mice per timepoint.\n",
    "\n",
    "## The Problem\n",
    "- **Sample size**: n=2 mice (1 sham, 1 UUO at each timepoint)\n",
    "- **Brutal truth**: Massively underpowered for most statistical tests\n",
    "- **Question**: What effect sizes CAN we detect? What should we NOT claim?\n",
    "\n",
    "## Statistical Framework\n",
    "- **Cohen's d**: Standardized effect size (mean difference / pooled SD)\n",
    "- **Power analysis**: For n=2, only **very large effects** (d > 2.0) are detectable\n",
    "- **Implication**: Focus on DESCRIPTIVE findings, not hypothesis testing\n",
    "\n",
    "## Analyses\n",
    "1. **Power curves**: Effect size vs statistical power for n=2\n",
    "2. **Observed effect sizes**: What Cohen's d do we actually see in data?\n",
    "3. **Confidence intervals**: Quantify uncertainty from small n\n",
    "4. **Recommendations**: What claims are justified vs unjustified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from typing import Tuple, List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root\n",
    "project_root = Path().resolve().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.config import Config\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Power Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohens_d(group1: np.ndarray, group2: np.ndarray) -> float:\n",
    "    \"\"\"Compute Cohen's d effect size.\n",
    "    \n",
    "    d = (mean1 - mean2) / pooled_std\n",
    "    \n",
    "    Interpretation:\n",
    "        |d| < 0.2: negligible\n",
    "        |d| < 0.5: small\n",
    "        |d| < 0.8: medium  \n",
    "        |d| >= 0.8: large\n",
    "        |d| >= 2.0: very large (required for n=2 detection)\n",
    "    \"\"\"\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    \n",
    "    # Pooled standard deviation\n",
    "    pooled_std = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))\n",
    "    \n",
    "    d = (np.mean(group1) - np.mean(group2)) / pooled_std\n",
    "    return d\n",
    "\n",
    "def power_ttest(n_per_group: int, effect_size: float, alpha: float = 0.05) -> float:\n",
    "    \"\"\"Compute statistical power for two-sample t-test.\n",
    "    \n",
    "    Power = P(reject H0 | H1 is true)\n",
    "    \n",
    "    Args:\n",
    "        n_per_group: Sample size per group\n",
    "        effect_size: Cohen's d\n",
    "        alpha: Significance level\n",
    "    \n",
    "    Returns:\n",
    "        Power (0 to 1)\n",
    "    \"\"\"\n",
    "    from scipy.stats import nct, t\n",
    "    \n",
    "    # Degrees of freedom\n",
    "    df = 2 * n_per_group - 2\n",
    "    \n",
    "    # Critical value (two-tailed)\n",
    "    t_crit = t.ppf(1 - alpha/2, df)\n",
    "    \n",
    "    # Non-centrality parameter\n",
    "    ncp = effect_size * np.sqrt(n_per_group / 2)\n",
    "    \n",
    "    # Power = P(|T| > t_crit | ncp)\n",
    "    power = 1 - (nct.cdf(t_crit, df, ncp) - nct.cdf(-t_crit, df, ncp))\n",
    "    \n",
    "    return power\n",
    "\n",
    "# Example: Power for n=2 per group\n",
    "print(\"Statistical Power for n=2 per group (Œ±=0.05):\")\n",
    "print(\"=\"*50)\n",
    "for d in [0.5, 0.8, 1.0, 1.5, 2.0, 3.0, 5.0]:\n",
    "    pwr = power_ttest(n_per_group=2, effect_size=d, alpha=0.05)\n",
    "    interpretation = \"ADEQUATE\" if pwr >= 0.8 else \"INADEQUATE\"\n",
    "    print(f\"Cohen's d = {d:.1f}: Power = {pwr:.3f}  [{interpretation}]\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  For 80% power with n=2, need Cohen's d ‚â• 3.0\")\n",
    "print(\"   This is an ENORMOUS effect (>99.9th percentile)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel A: Power Curves for Different Sample Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate power curves\n",
    "effect_sizes = np.linspace(0, 4, 100)\n",
    "sample_sizes = [2, 3, 5, 10, 20]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for n in sample_sizes:\n",
    "    powers = [power_ttest(n, d) for d in effect_sizes]\n",
    "    label = f\"n={n}\" + (\" (OUR STUDY)\" if n == 2 else \"\")\n",
    "    linewidth = 3 if n == 2 else 1.5\n",
    "    alpha = 1.0 if n == 2 else 0.6\n",
    "    ax.plot(effect_sizes, powers, label=label, linewidth=linewidth, alpha=alpha)\n",
    "\n",
    "# Reference lines\n",
    "ax.axhline(0.8, color='red', linestyle='--', linewidth=1, label='80% power (target)')\n",
    "ax.axvline(2.0, color='orange', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('Effect Size (Cohen\\'s d)', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Statistical Power', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Panel A: Statistical Power vs Effect Size\\n(Two-sample t-test, Œ±=0.05)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_xlim(0, 4)\n",
    "\n",
    "# Annotation\n",
    "ax.annotate('n=2 reaches 80% power\\nonly at d ‚âà 3.0', \n",
    "            xy=(3.0, 0.8), xytext=(2.2, 0.5),\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2),\n",
    "            fontsize=10, color='red', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Panel A shows:\")\n",
    "print(\"   - n=2 has VERY LOW power for typical effect sizes (d < 2.0)\")\n",
    "print(\"   - 80% power requires d ‚â• 3.0 (extreme effect)\")\n",
    "print(\"   - Even n=5 dramatically improves detectability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel B: Observed Effect Sizes in Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load results\n",
    "config = Config.from_json(project_root / 'config.json')\n",
    "results_dir = Path(config.output_dir)\n",
    "\n",
    "# Load ROI-level summary data\n",
    "summary_file = results_dir / 'cross_sectional_kidney_injury' / 'roi_summary_statistics.csv'\n",
    "\n",
    "if summary_file.exists():\n",
    "    roi_summary = pd.read_csv(summary_file)\n",
    "    print(f\"Loaded {len(roi_summary)} ROI summaries\")\n",
    "    print(f\"Columns: {list(roi_summary.columns[:10])}...\")\n",
    "    \n",
    "    # Extract timepoints\n",
    "    timepoints = roi_summary['timepoint'].unique()\n",
    "    print(f\"Timepoints: {timepoints}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Summary file not found: {summary_file}\")\n",
    "    print(\"   Generating synthetic example data for demonstration\")\n",
    "    \n",
    "    # Synthetic data for demonstration\n",
    "    np.random.seed(42)\n",
    "    roi_summary = pd.DataFrame({\n",
    "        'roi_name': [f'ROI_{i:02d}' for i in range(8)],\n",
    "        'timepoint': ['sham', 'sham', 'd1', 'd1', 'd3', 'd3', 'd7', 'd7'],\n",
    "        'total_superpixels': np.random.randint(1000, 3000, 8),\n",
    "        'neutrophil_prop': np.random.rand(8) * 0.3,\n",
    "        'm2_macrophage_prop': np.random.rand(8) * 0.2,\n",
    "        'activated_immune_prop': np.random.rand(8) * 0.15\n",
    "    })\n",
    "    timepoints = roi_summary['timepoint'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute effect sizes between timepoints\n",
    "# Example: Sham vs each injury timepoint\n",
    "\n",
    "metrics_to_test = [col for col in roi_summary.columns \n",
    "                   if col.endswith('_prop') or col == 'total_superpixels']\n",
    "\n",
    "effect_sizes = []\n",
    "\n",
    "sham_data = roi_summary[roi_summary['timepoint'] == 'sham']\n",
    "\n",
    "for tp in ['d1', 'd3', 'd7']:\n",
    "    if tp not in timepoints:\n",
    "        continue\n",
    "        \n",
    "    injury_data = roi_summary[roi_summary['timepoint'] == tp]\n",
    "    \n",
    "    for metric in metrics_to_test:\n",
    "        if metric not in sham_data.columns or metric not in injury_data.columns:\n",
    "            continue\n",
    "            \n",
    "        sham_vals = sham_data[metric].dropna().values\n",
    "        injury_vals = injury_data[metric].dropna().values\n",
    "        \n",
    "        if len(sham_vals) >= 2 and len(injury_vals) >= 2:\n",
    "            d = cohens_d(sham_vals, injury_vals)\n",
    "            \n",
    "            # Compute p-value (though underpowered)\n",
    "            t_stat, p_val = stats.ttest_ind(sham_vals, injury_vals)\n",
    "            \n",
    "            effect_sizes.append({\n",
    "                'comparison': f'Sham vs {tp.upper()}',\n",
    "                'metric': metric,\n",
    "                'cohens_d': d,\n",
    "                'abs_d': abs(d),\n",
    "                'p_value': p_val,\n",
    "                'n_sham': len(sham_vals),\n",
    "                'n_injury': len(injury_vals),\n",
    "                'detectable': abs(d) >= 2.0  # Threshold for n=2\n",
    "            })\n",
    "\n",
    "effect_df = pd.DataFrame(effect_sizes)\n",
    "\n",
    "if not effect_df.empty:\n",
    "    print(f\"\\nComputed {len(effect_df)} effect sizes\")\n",
    "    print(f\"\\nTop 10 largest effects:\")\n",
    "    print(effect_df.nlargest(10, 'abs_d')[['comparison', 'metric', 'cohens_d', 'p_value', 'detectable']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel B: Distribution of observed effect sizes\n",
    "if not effect_df.empty:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Left: Histogram of effect sizes\n",
    "    ax = axes[0]\n",
    "    ax.hist(effect_df['abs_d'], bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(0.8, color='green', linestyle='--', linewidth=2, label='Large effect (d=0.8)')\n",
    "    ax.axvline(2.0, color='red', linestyle='--', linewidth=2, label='Detectable with n=2 (d=2.0)')\n",
    "    ax.set_xlabel('|Cohen\\'s d|', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel('Count', fontweight='bold', fontsize=12)\n",
    "    ax.set_title('Distribution of Observed Effect Sizes', fontsize=12, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Right: Effect size vs p-value\n",
    "    ax = axes[1]\n",
    "    colors = ['red' if d >= 2.0 else 'orange' if d >= 0.8 else 'gray' \n",
    "              for d in effect_df['abs_d']]\n",
    "    ax.scatter(effect_df['abs_d'], -np.log10(effect_df['p_value']), \n",
    "               c=colors, s=50, alpha=0.6, edgecolors='black', linewidths=0.5)\n",
    "    ax.axvline(2.0, color='red', linestyle='--', linewidth=2, alpha=0.5, label='d=2.0 threshold')\n",
    "    ax.axhline(-np.log10(0.05), color='blue', linestyle='--', linewidth=1, alpha=0.5, label='p=0.05')\n",
    "    ax.set_xlabel('|Cohen\\'s d|', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel('-log10(p-value)', fontweight='bold', fontsize=12)\n",
    "    ax.set_title('Effect Size vs Statistical Significance', fontsize=12, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Panel B: Observed Effect Sizes in UUO Kidney Dataset (n=2)', \n",
    "                 fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary\n",
    "    n_detectable = (effect_df['abs_d'] >= 2.0).sum()\n",
    "    pct_detectable = (n_detectable / len(effect_df)) * 100\n",
    "    \n",
    "    print(f\"\\nüìä Panel B findings:\")\n",
    "    print(f\"   - {len(effect_df)} comparisons analyzed\")\n",
    "    print(f\"   - {n_detectable} ({pct_detectable:.1f}%) have |d| ‚â• 2.0 (detectable)\")\n",
    "    print(f\"   - Median effect size: {effect_df['abs_d'].median():.2f}\")\n",
    "    print(f\"   - Range: [{effect_df['abs_d'].min():.2f}, {effect_df['abs_d'].max():.2f}]\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No effect sizes computed - check data availability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel C: Confidence Intervals for n=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(data: np.ndarray, statistic=np.mean, n_boot: int = 10000, ci: float = 95) -> Tuple[float, float]:\n",
    "    \"\"\"Bootstrap confidence interval for a statistic.\n",
    "    \n",
    "    Args:\n",
    "        data: Sample data\n",
    "        statistic: Function to compute (default: mean)\n",
    "        n_boot: Number of bootstrap samples\n",
    "        ci: Confidence level (e.g., 95 for 95% CI)\n",
    "    \n",
    "    Returns:\n",
    "        (lower, upper) confidence bounds\n",
    "    \"\"\"\n",
    "    boot_stats = []\n",
    "    n = len(data)\n",
    "    \n",
    "    for _ in range(n_boot):\n",
    "        sample = np.random.choice(data, size=n, replace=True)\n",
    "        boot_stats.append(statistic(sample))\n",
    "    \n",
    "    alpha = (100 - ci) / 2\n",
    "    lower = np.percentile(boot_stats, alpha)\n",
    "    upper = np.percentile(boot_stats, 100 - alpha)\n",
    "    \n",
    "    return lower, upper\n",
    "\n",
    "# Example: CI width vs sample size\n",
    "sample_sizes = [2, 3, 5, 10, 20, 50]\n",
    "ci_widths = []\n",
    "\n",
    "np.random.seed(42)\n",
    "population = np.random.normal(10, 2, 10000)  # Ground truth\n",
    "\n",
    "for n in sample_sizes:\n",
    "    widths = []\n",
    "    for trial in range(100):  # Multiple trials\n",
    "        sample = np.random.choice(population, size=n, replace=False)\n",
    "        lower, upper = bootstrap_ci(sample, n_boot=1000)\n",
    "        widths.append(upper - lower)\n",
    "    ci_widths.append(np.mean(widths))\n",
    "\n",
    "# Panel C: CI width vs sample size\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(sample_sizes, ci_widths, 'o-', linewidth=2, markersize=10, color='steelblue')\n",
    "ax.scatter([2], [ci_widths[0]], s=200, color='red', zorder=10, \n",
    "           label=f'n=2 (OUR STUDY): CI width ‚âà {ci_widths[0]:.2f}')\n",
    "\n",
    "ax.set_xlabel('Sample Size (n)', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Mean 95% CI Width', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Panel C: Uncertainty (CI Width) vs Sample Size\\n(Bootstrap 95% CI for mean)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(alpha=0.3)\n",
    "ax.set_xscale('log')\n",
    "ax.set_xticks(sample_sizes)\n",
    "ax.set_xticklabels(sample_sizes)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Panel C shows:\")\n",
    "print(f\"   - n=2 produces CI ~{ci_widths[0]/ci_widths[-1]:.1f}√ó wider than n=50\")\n",
    "print(f\"   - Massive uncertainty from small sample size\")\n",
    "print(f\"   - Even n=5 drastically improves precision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations for Methods Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"STATISTICAL POWER ANALYSIS - RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  JUSTIFIED CLAIMS (n=2):\")\n",
    "print(\"   ‚úÖ DESCRIPTIVE findings (trends, patterns observed)\")\n",
    "print(\"   ‚úÖ QUALITATIVE comparisons (higher/lower, present/absent)\")\n",
    "print(\"   ‚úÖ HYPOTHESIS GENERATION (what to test in powered study)\")\n",
    "print(\"   ‚úÖ METHODS DEMONSTRATION (pipeline works on real data)\")\n",
    "print(\"   ‚úÖ VERY LARGE effects (Cohen's d > 2.0) cautiously\")\n",
    "\n",
    "print(\"\\n‚ùå UNJUSTIFIED CLAIMS (n=2):\")\n",
    "print(\"   ‚ùå Statistical significance (p-values are meaningless)\")\n",
    "print(\"   ‚ùå Causal inference (no statistical power)\")\n",
    "print(\"   ‚ùå Subtle effects (d < 2.0 undetectable)\")\n",
    "print(\"   ‚ùå Generalization to population (pilot data only)\")\n",
    "print(\"   ‚ùå Definitive biological conclusions\")\n",
    "\n",
    "print(\"\\nüìù METHODS PAPER FRAMING:\")\n",
    "print(\"   'This pilot study (n=2 mice per timepoint) demonstrates\")\n",
    "print(\"   our pipeline's capability to extract spatial patterns from\")\n",
    "print(\"   limited IMC data. Statistical power analysis reveals that\")\n",
    "print(\"   only very large effects (Cohen's d > 2.0) are detectable,\")\n",
    "print(\"   necessitating cautious interpretation. Findings are descriptive\")\n",
    "print(\"   and hypothesis-generating, not confirmatory.'\")\n",
    "\n",
    "print(\"\\nüí° HONEST ASSESSMENT:\")\n",
    "print(\"   - n=2 is a PILOT study, not a powered experiment\")\n",
    "print(\"   - Appropriate for METHODS paper (demonstrates capability)\")\n",
    "print(\"   - NOT appropriate for discovery paper (underpowered)\")\n",
    "print(\"   - Brutal but true: Most observed effects are UNDERPOWERED\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Findings\n",
    "1. **n=2 requires Cohen's d ‚â• 3.0 for 80% power** (extreme effect)\n",
    "2. **Most biological effects are d < 2.0** (medium-large)\n",
    "3. **Confidence intervals are ~5√ó wider** than adequately powered study\n",
    "\n",
    "### Implications\n",
    "- Frame as **methods demonstration**, not biological discovery\n",
    "- Report **effect sizes**, not p-values\n",
    "- Acknowledge **limitations explicitly**\n",
    "- Focus on **descriptive patterns**\n",
    "\n",
    "### For Publication\n",
    "This analysis will be cited in methods paper to demonstrate:\n",
    "- ‚úÖ We understand statistical limitations\n",
    "- ‚úÖ Claims are appropriately scoped\n",
    "- ‚úÖ Honest about pilot nature of data\n",
    "- ‚úÖ Methods validated on real data despite small n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
