{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Effect Size Analysis for n=2 Spatial Biology Study\n",
    "\n",
    "## The Statistical Reality\n",
    "\n",
    "**Ground truth**: We have n=2 mice per timepoint. This cannot be transmuted into n=4,000 through statistical modeling.\n",
    "\n",
    "**But**: We can leverage hierarchical spatial structure to build confidence WITHOUT pseudo-replication:\n",
    "\n",
    "```\n",
    "Sham condition:\n",
    "  Mouse 1: 3 ROIs √ó ~2,000 superpixels each\n",
    "  Mouse 2: 3 ROIs √ó ~2,000 superpixels each\n",
    "\n",
    "UUO D1:\n",
    "  Mouse 1: 3 ROIs √ó ~2,000 superpixels each  \n",
    "  Mouse 2: 3 ROIs √ó ~2,000 superpixels each\n",
    "```\n",
    "\n",
    "## The Honest Approach\n",
    "\n",
    "1. **Within-mouse effect sizes**: Calculate effect within each individual mouse\n",
    "2. **Across-ROI consistency**: Do all 3 ROIs within a mouse show same direction?\n",
    "3. **Across-mouse consistency**: Do both mice show same pattern?\n",
    "4. **Multi-scale coherence**: Is effect visible at cell, superpixel, ROI, and mouse levels?\n",
    "\n",
    "**Key insight**: We're testing CONSISTENCY, not statistical significance.\n",
    "- If effect is d=2.5 in Mouse 1 and d=2.3 in Mouse 2 ‚Üí Consistent\n",
    "- If effect is d=2.5 in Mouse 1 and d=-0.3 in Mouse 2 ‚Üí Inconsistent (biological variability)\n",
    "\n",
    "## What We CAN Claim\n",
    "\n",
    "‚úÖ \"Effect observed consistently across all biological replicates\"\n",
    "‚úÖ \"Within-mouse effect sizes are large (d > 2.0) with consistent direction\"\n",
    "‚úÖ \"Pattern robust across hierarchical scales (cell ‚Üí superpixel ‚Üí ROI ‚Üí mouse)\"\n",
    "‚úÖ \"Results align with published UUO literature, adding spatial resolution\"\n",
    "\n",
    "## What We CANNOT Claim\n",
    "\n",
    "‚ùå \"Statistically significant at p<0.05\" (underpowered)\n",
    "‚ùå \"Generalizes to all C57BL/6 mice\" (n=2 insufficient)\n",
    "‚ùå \"Superpixels are independent replicates\" (pseudo-replication)\n",
    "‚ùå \"Mixed-effects modeling provides statistical power\" (with n=2, it doesn't)\n",
    "\n",
    "---\n",
    "\n",
    "**This notebook demonstrates the honest approach to small-n spatial biology.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import json\n",
    "import gzip\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root\n",
    "project_root = Path().resolve().parent.parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "from src.config import Config\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Hierarchical Data Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load kidney config\nconfig = Config(str(project_root / 'config.json.backup'))\nresults_dir = project_root / 'results'\nroi_results_dir = results_dir / 'roi_results'\n\nmarkers = config.proteins\nprint(f\"Analyzing {len(markers)} protein markers: {', '.join(markers)}\")\n\n# Parse ROI file structure - Include BOTH Sham controls and UUO timepoints\nall_roi_files = sorted(roi_results_dir.glob('roi_*.json.gz'))\n\n# Filter for kidney data: Sham (Sam1/Sam2) + UUO timepoints (D1/D3/D7)\nroi_files = [f for f in all_roi_files if 'IMC_241218_Alun' in f.name and \n             (any(f'_D{i}_' in f.name for i in [1, 3, 7]) or '_Sam' in f.name)]\n\nprint(f\"\\nFound {len(roi_files)} kidney ROI files:\")\nprint(f\"  - Sham controls: {len([f for f in roi_files if 'Sam' in f.name])} ROIs\")\nprint(f\"  - UUO timepoints: {len([f for f in roi_files if any(f'_D{i}_' in f.name for i in [1,3,7])])} ROIs\")\n\n# Extract metadata from filenames\ndef parse_roi_name(filename: str) -> Dict[str, str]:\n    \\\"\\\"\\\"Extract condition, timepoint, mouse, and ROI from filename.\n    \n    Examples:\n      roi_IMC_241218_Alun_ROI_Sam1_01_2_results.json.gz\n      ‚Üí {'condition': 'Sham', 'timepoint': 'Sham', 'mouse': 'Sam1', 'roi_num': '01'}\n      \n      roi_IMC_241218_Alun_ROI_D1_M1_01_9_results.json.gz\n      ‚Üí {'condition': 'UUO', 'timepoint': 'D1', 'mouse': 'M1', 'roi_num': '01'}\n    \\\"\\\"\\\"\n    clean_name = filename.replace('.json.gz', '').replace('.json', '').replace('_results', '')\n    parts = clean_name.split('_')\n    \n    # Determine if Sham or UUO\n    if 'Sam' in clean_name:\n        # Sham control\n        sam_idx = next(i for i, p in enumerate(parts) if p.startswith('Sam'))\n        mouse_id = parts[sam_idx]\n        roi_idx = sam_idx + 1\n        \n        return {\n            'condition': 'Sham',\n            'timepoint': 'Sham',\n            'mouse': mouse_id,\n            'roi_num': parts[roi_idx],\n            'full_name': clean_name,\n            'group': f'Sham_{mouse_id}'\n        }\n    else:\n        # UUO timepoint\n        tp_idx = next(i for i, p in enumerate(parts) if p.startswith('D'))\n        mouse_idx = tp_idx + 1\n        roi_idx = mouse_idx + 1\n        \n        timepoint = parts[tp_idx]\n        mouse_id = parts[mouse_idx]\n        \n        return {\n            'condition': 'UUO',\n            'timepoint': timepoint,\n            'mouse': mouse_id,\n            'roi_num': parts[roi_idx],\n            'full_name': clean_name,\n            'group': f'{timepoint}_{mouse_id}'\n        }\n\n# Build hierarchical index\nroi_metadata = []\nfor f in roi_files:\n    meta = parse_roi_name(f.name)\n    meta['file_path'] = f\n    roi_metadata.append(meta)\n\nroi_df = pd.DataFrame(roi_metadata)\n\n# Display hierarchical structure\nprint(f\\\"\\nHierarchical structure (n={len(roi_df)} ROIs total):\\\")\nprint(\\\"\\\\nBy condition and timepoint:\\\")\nprint(roi_df.groupby(['condition', 'timepoint', 'mouse']).size())\n\nprint(f\\\"\\nTotal mice: {len(roi_df.group.unique())} (2 Sham + 2√ó3 UUO timepoints)\\\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Superpixel-Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_superpixel_features(roi_file: Path, scale: float = 10.0) -> pd.DataFrame:\n",
    "    \"\"\"Load superpixel-level protein features from ROI results.\n",
    "    \n",
    "    Args:\n",
    "        roi_file: Path to compressed JSON results\n",
    "        scale: Spatial scale in microns (10.0, 20.0, 40.0)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with superpixel features and coordinates\n",
    "    \"\"\"\n",
    "    with gzip.open(roi_file, 'rt') as f:\n",
    "        results = json.load(f)\n",
    "    \n",
    "    # Extract scale data\n",
    "    scale_key = str(float(scale))\n",
    "    scale_data = results['multiscale_results'][scale_key]\n",
    "    \n",
    "    # Reconstruct features array\n",
    "    features_data = scale_data['features']\n",
    "    shape = features_data['shape']\n",
    "    data_flat = features_data['data']\n",
    "    features_array = np.array(data_flat).reshape(shape)\n",
    "    \n",
    "    # Get protein columns (first n_proteins columns)\n",
    "    n_proteins = len(markers)\n",
    "    protein_features = features_array[:, :n_proteins]\n",
    "    \n",
    "    # Reconstruct coordinates\n",
    "    coords_data = scale_data['coordinates']\n",
    "    coords_array = np.array(coords_data['data']).reshape(coords_data['shape'])\n",
    "    \n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(protein_features, columns=markers)\n",
    "    df['x'] = coords_array[:, 0]\n",
    "    df['y'] = coords_array[:, 1]\n",
    "    df['superpixel_id'] = np.arange(len(df))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Test loading\n",
    "test_file = roi_files[0]\n",
    "test_meta = parse_roi_name(test_file.name)\n",
    "test_df = load_superpixel_features(test_file)\n",
    "print(f\"\\nLoaded {test_meta['full_name']}:\")\n",
    "print(f\"  {len(test_df):,} superpixels\")\n",
    "print(f\"  {len(markers)} protein markers\")\n",
    "print(f\"  Spatial extent: x=[{test_df.x.min():.1f}, {test_df.x.max():.1f}], y=[{test_df.y.min():.1f}, {test_df.y.max():.1f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel A: Within-Mouse Effect Sizes Across ROIs\n",
    "\n",
    "**The key test**: If we have 3 ROIs from the same mouse, do they all show the same biological pattern?\n",
    "\n",
    "This tests **within-mouse consistency** which is independent of between-mouse statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohens_d(group1: np.ndarray, group2: np.ndarray) -> float:\n",
    "    \"\"\"Cohen's d effect size.\"\"\"\n",
    "    n1, n2 = len(group1), len(group2)\n",
    "    var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)\n",
    "    pooled_std = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))\n",
    "    return (np.mean(group1) - np.mean(group2)) / pooled_std\n",
    "\n",
    "# For each mouse, compute effect size for each marker\n",
    "# by comparing all superpixels in that mouse's ROIs\n",
    "# This gives us WITHIN-MOUSE effect estimates\n",
    "\n",
    "within_mouse_effects = []\n",
    "\n",
    "for timepoint in ['D1', 'D3', 'D7']:\n",
    "    for mouse in ['M1', 'M2']:\n",
    "        # Get all ROIs for this mouse\n",
    "        mouse_rois = roi_df[(roi_df.timepoint == timepoint) & (roi_df.mouse == mouse)]\n",
    "        \n",
    "        if len(mouse_rois) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Load all superpixels from this mouse's ROIs\n",
    "        all_superpixels = []\n",
    "        for _, row in mouse_rois.iterrows():\n",
    "            sp_df = load_superpixel_features(row['file_path'])\n",
    "            sp_df['roi'] = row['roi_num']\n",
    "            all_superpixels.append(sp_df)\n",
    "        \n",
    "        combined = pd.concat(all_superpixels, ignore_index=True)\n",
    "        \n",
    "        # For each marker, compute pairwise effect sizes between ROIs\n",
    "        roi_nums = sorted(combined['roi'].unique())\n",
    "        \n",
    "        for marker in markers:\n",
    "            # Compute effect between each pair of ROIs within this mouse\n",
    "            for i, roi1 in enumerate(roi_nums):\n",
    "                for roi2 in roi_nums[i+1:]:\n",
    "                    data1 = combined[combined.roi == roi1][marker].values\n",
    "                    data2 = combined[combined.roi == roi2][marker].values\n",
    "                    \n",
    "                    d = cohens_d(data1, data2)\n",
    "                    \n",
    "                    within_mouse_effects.append({\n",
    "                        'timepoint': timepoint,\n",
    "                        'mouse': mouse,\n",
    "                        'marker': marker,\n",
    "                        'roi_pair': f'{roi1} vs {roi2}',\n",
    "                        'cohens_d': d,\n",
    "                        'abs_d': abs(d),\n",
    "                        'n_roi1': len(data1),\n",
    "                        'n_roi2': len(data2)\n",
    "                    })\n",
    "\n",
    "within_df = pd.DataFrame(within_mouse_effects)\n",
    "print(f\"\\nComputed {len(within_df)} within-mouse ROI comparisons\")\n",
    "print(f\"Median within-mouse effect: |d| = {within_df['abs_d'].median():.3f}\")\n",
    "print(f\"This represents biological/technical heterogeneity WITHIN mouse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel A: Distribution of within-mouse effect sizes\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Left: Histogram\n",
    "ax = axes[0]\n",
    "ax.hist(within_df['abs_d'], bins=50, color='gray', alpha=0.7, edgecolor='black')\n",
    "ax.axvline(within_df['abs_d'].median(), color='blue', linestyle='--', linewidth=2,\n",
    "           label=f'Median = {within_df[\"abs_d\"].median():.3f}')\n",
    "ax.axvline(0.5, color='orange', linestyle='--', linewidth=1.5, alpha=0.6, label='Medium effect (d=0.5)')\n",
    "ax.set_xlabel('|Cohen\\'s d|', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Count', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Within-Mouse ROI Heterogeneity\\n(Biological + Technical Variation)', fontsize=12, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Right: By timepoint/mouse\n",
    "ax = axes[1]\n",
    "for tp in ['D1', 'D3', 'D7']:\n",
    "    tp_data = within_df[within_df.timepoint == tp]\n",
    "    ax.scatter([tp] * len(tp_data), tp_data['abs_d'], alpha=0.3, s=20)\n",
    "    \n",
    "    # Show median per timepoint\n",
    "    median = tp_data['abs_d'].median()\n",
    "    ax.scatter([tp], [median], color='red', s=200, marker='D', zorder=10, edgecolors='black', linewidths=2)\n",
    "\n",
    "ax.set_xlabel('Timepoint', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('|Cohen\\'s d|', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Within-Mouse Heterogeneity by Timepoint\\n(Red diamonds = median)', fontsize=12, fontweight='bold')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('Panel A: Baseline Biological Variability (ROIs within Same Mouse)', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Interpretation:\")\n",
    "print(f\"   - Median within-mouse variation: |d| = {within_df['abs_d'].median():.3f}\")\n",
    "print(f\"   - This sets the BASELINE for what 'consistent' means\")\n",
    "print(f\"   - Between-condition effects > {within_df['abs_d'].quantile(0.9):.3f} (90th percentile) are notable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Panel B: Primary Biological Effect (Sham vs UUO D7)\n\n**The most important comparison**: Healthy tissue vs late injury (7 days post-UUO)\n\n**Key**: We compute effect at MOUSE level (pooling all ROIs within mouse), then check consistency across the n=2 biological replicates."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sham data (if exists in our dataset)\n",
    "# Note: Our current data may only have UUO timepoints (D1, D3, D7)\n",
    "# For demonstration, we'll compare D1 vs D7 to show temporal progression\n",
    "\n",
    "print(\"Available data:\")\n",
    "print(roi_df.groupby(['timepoint', 'mouse']).size())\n",
    "\n",
    "# Strategy: Compare early (D1) vs late (D7) as demonstration of temporal effect\n",
    "# This shows the methodology even if we don't have true sham controls\n",
    "\n",
    "between_condition_effects = []\n",
    "\n",
    "# For each marker, compare D1 vs D7\n",
    "for mouse in ['M1', 'M2']:\n",
    "    # Load all D1 ROIs for this mouse\n",
    "    d1_rois = roi_df[(roi_df.timepoint == 'D1') & (roi_df.mouse == mouse)]\n",
    "    d1_data = []\n",
    "    for _, row in d1_rois.iterrows():\n",
    "        sp_df = load_superpixel_features(row['file_path'])\n",
    "        d1_data.append(sp_df)\n",
    "    d1_combined = pd.concat(d1_data, ignore_index=True) if d1_data else None\n",
    "    \n",
    "    # Load all D7 ROIs for this mouse\n",
    "    d7_rois = roi_df[(roi_df.timepoint == 'D7') & (roi_df.mouse == mouse)]\n",
    "    d7_data = []\n",
    "    for _, row in d7_rois.iterrows():\n",
    "        sp_df = load_superpixel_features(row['file_path'])\n",
    "        d7_data.append(sp_df)\n",
    "    d7_combined = pd.concat(d7_data, ignore_index=True) if d7_data else None\n",
    "    \n",
    "    if d1_combined is None or d7_combined is None:\n",
    "        continue\n",
    "    \n",
    "    # Compute effect size for each marker\n",
    "    for marker in markers:\n",
    "        d1_vals = d1_combined[marker].values\n",
    "        d7_vals = d7_combined[marker].values\n",
    "        \n",
    "        d = cohens_d(d1_vals, d7_vals)\n",
    "        \n",
    "        between_condition_effects.append({\n",
    "            'mouse': mouse,\n",
    "            'marker': marker,\n",
    "            'comparison': 'D1 vs D7',\n",
    "            'cohens_d': d,\n",
    "            'abs_d': abs(d),\n",
    "            'n_d1': len(d1_vals),\n",
    "            'n_d7': len(d7_vals)\n",
    "        })\n",
    "\n",
    "between_df = pd.DataFrame(between_condition_effects)\n",
    "\n",
    "if not between_df.empty:\n",
    "    print(f\"\\nComputed {len(between_df)} between-timepoint comparisons\")\n",
    "    print(f\"Median between-timepoint effect: |d| = {between_df['abs_d'].median():.3f}\")\n",
    "    print(f\"\\nTop 5 largest effects:\")\n",
    "    print(between_df.nlargest(5, 'abs_d')[['marker', 'mouse', 'cohens_d', 'abs_d']])\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No between-timepoint data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Panel B: Consistency check across mice\n",
    "if not between_df.empty:\n",
    "    # For each marker, compare effect in M1 vs M2\n",
    "    consistency_check = []\n",
    "    \n",
    "    for marker in markers:\n",
    "        m1_effect = between_df[(between_df.mouse == 'M1') & (between_df.marker == marker)]['cohens_d'].values\n",
    "        m2_effect = between_df[(between_df.mouse == 'M2') & (between_df.marker == marker)]['cohens_d'].values\n",
    "        \n",
    "        if len(m1_effect) > 0 and len(m2_effect) > 0:\n",
    "            d_m1 = m1_effect[0]\n",
    "            d_m2 = m2_effect[0]\n",
    "            \n",
    "            same_direction = np.sign(d_m1) == np.sign(d_m2)\n",
    "            magnitude_diff = abs(d_m1 - d_m2)\n",
    "            \n",
    "            consistency_check.append({\n",
    "                'marker': marker,\n",
    "                'd_M1': d_m1,\n",
    "                'd_M2': d_m2,\n",
    "                'mean_d': (d_m1 + d_m2) / 2,\n",
    "                'abs_mean_d': abs((d_m1 + d_m2) / 2),\n",
    "                'same_direction': same_direction,\n",
    "                'magnitude_diff': magnitude_diff\n",
    "            })\n",
    "    \n",
    "    consistency_df = pd.DataFrame(consistency_check)\n",
    "    \n",
    "    # Plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Left: M1 vs M2 effect sizes\n",
    "    ax = axes[0]\n",
    "    colors = ['green' if same_dir else 'red' for same_dir in consistency_df['same_direction']]\n",
    "    ax.scatter(consistency_df['d_M1'], consistency_df['d_M2'], c=colors, s=80, alpha=0.6, edgecolors='black')\n",
    "    \n",
    "    # Diagonal line (perfect agreement)\n",
    "    lim = max(abs(consistency_df['d_M1']).max(), abs(consistency_df['d_M2']).max()) * 1.1\n",
    "    ax.plot([-lim, lim], [-lim, lim], 'k--', linewidth=1, alpha=0.5, label='Perfect agreement')\n",
    "    ax.axhline(0, color='gray', linewidth=0.5)\n",
    "    ax.axvline(0, color='gray', linewidth=0.5)\n",
    "    \n",
    "    ax.set_xlabel('Effect Size in Mouse 1 (Cohen\\'s d)', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel('Effect Size in Mouse 2 (Cohen\\'s d)', fontweight='bold', fontsize=12)\n",
    "    ax.set_title('Consistency Across Biological Replicates\\n(Green = same direction, Red = opposite)', fontsize=12, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_xlim(-lim, lim)\n",
    "    ax.set_ylim(-lim, lim)\n",
    "    \n",
    "    # Right: Ranked effect sizes with error bars\n",
    "    ax = axes[1]\n",
    "    consistency_df_sorted = consistency_df.sort_values('abs_mean_d', ascending=False).reset_index(drop=True)\n",
    "    x = np.arange(len(consistency_df_sorted))\n",
    "    \n",
    "    # Plot mean effect with range\n",
    "    ax.scatter(x, consistency_df_sorted['mean_d'], c='steelblue', s=100, zorder=3, edgecolors='black', linewidths=1.5)\n",
    "    \n",
    "    # Error bars showing range between M1 and M2\n",
    "    for i, row in consistency_df_sorted.iterrows():\n",
    "        ax.plot([i, i], [row['d_M1'], row['d_M2']], color='gray', linewidth=2, alpha=0.5)\n",
    "    \n",
    "    ax.axhline(0, color='black', linewidth=1)\n",
    "    ax.axhline(2.0, color='red', linestyle='--', linewidth=1.5, alpha=0.5, label='Large effect (d=2.0)')\n",
    "    ax.axhline(-2.0, color='red', linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "    \n",
    "    ax.set_xlabel('Marker (ranked by |effect|)', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel('Cohen\\'s d (D1‚ÜíD7 change)', fontweight='bold', fontsize=12)\n",
    "    ax.set_title('Between-Mouse Consistency\\n(Points = mean, Bars = M1-M2 range)', fontsize=12, fontweight='bold')\n",
    "    ax.set_xticks(x[::2])  # Show every other marker\n",
    "    ax.set_xticklabels(consistency_df_sorted['marker'][::2], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle('Panel B: Effect Consistency Across n=2 Biological Replicates', fontsize=14, fontweight='bold', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    n_consistent = consistency_df['same_direction'].sum()\n",
    "    pct_consistent = (n_consistent / len(consistency_df)) * 100\n",
    "    median_diff = consistency_df['magnitude_diff'].median()\n",
    "    \n",
    "    print(f\"\\nüìä Consistency Analysis:\")\n",
    "    print(f\"   - {n_consistent}/{len(consistency_df)} markers ({pct_consistent:.1f}%) show same direction in both mice\")\n",
    "    print(f\"   - Median M1-M2 magnitude difference: {median_diff:.3f}\")\n",
    "    print(f\"   - Compare to within-mouse variation: {within_df['abs_d'].median():.3f}\")\n",
    "    \n",
    "    # Identify highly consistent large effects\n",
    "    large_consistent = consistency_df[\n",
    "        (consistency_df['abs_mean_d'] > 1.0) & \n",
    "        (consistency_df['same_direction']) &\n",
    "        (consistency_df['magnitude_diff'] < 1.0)\n",
    "    ]\n",
    "    \n",
    "    if len(large_consistent) > 0:\n",
    "        print(f\"\\n‚úÖ Robust findings (large effect + consistent direction + similar magnitude):\")\n",
    "        for _, row in large_consistent.iterrows():\n",
    "            print(f\"   - {row['marker']}: d={row['mean_d']:.2f} (M1={row['d_M1']:.2f}, M2={row['d_M2']:.2f})\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Cannot compute Panel B - insufficient data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel C: Multi-Scale Coherence\n",
    "\n",
    "**Final test**: Is the effect visible at multiple spatial scales?\n",
    "\n",
    "If we see consistent pattern at 10Œºm, 20Œºm, and 40Œºm scales, this suggests a robust biological phenomenon rather than scale-specific artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For top marker (largest consistent effect), compute effect size at each scale\n",
    "if not consistency_df.empty and len(large_consistent) > 0:\n",
    "    top_marker = large_consistent.nlargest(1, 'abs_mean_d').iloc[0]['marker']\n",
    "    print(f\"Examining multi-scale coherence for: {top_marker}\")\n",
    "    \n",
    "    multiscale_effects = []\n",
    "    \n",
    "    for scale in [10.0, 20.0, 40.0]:\n",
    "        for mouse in ['M1', 'M2']:\n",
    "            # Load D1 data at this scale\n",
    "            d1_rois = roi_df[(roi_df.timepoint == 'D1') & (roi_df.mouse == mouse)]\n",
    "            d1_data = []\n",
    "            for _, row in d1_rois.iterrows():\n",
    "                sp_df = load_superpixel_features(row['file_path'], scale=scale)\n",
    "                d1_data.append(sp_df)\n",
    "            d1_combined = pd.concat(d1_data, ignore_index=True) if d1_data else None\n",
    "            \n",
    "            # Load D7 data at this scale\n",
    "            d7_rois = roi_df[(roi_df.timepoint == 'D7') & (roi_df.mouse == mouse)]\n",
    "            d7_data = []\n",
    "            for _, row in d7_rois.iterrows():\n",
    "                sp_df = load_superpixel_features(row['file_path'], scale=scale)\n",
    "                d7_data.append(sp_df)\n",
    "            d7_combined = pd.concat(d7_data, ignore_index=True) if d7_data else None\n",
    "            \n",
    "            if d1_combined is None or d7_combined is None:\n",
    "                continue\n",
    "            \n",
    "            # Compute effect at this scale\n",
    "            d1_vals = d1_combined[top_marker].values\n",
    "            d7_vals = d7_combined[top_marker].values\n",
    "            \n",
    "            d = cohens_d(d1_vals, d7_vals)\n",
    "            \n",
    "            multiscale_effects.append({\n",
    "                'scale_um': scale,\n",
    "                'mouse': mouse,\n",
    "                'cohens_d': d,\n",
    "                'abs_d': abs(d),\n",
    "                'n_d1': len(d1_vals),\n",
    "                'n_d7': len(d7_vals)\n",
    "            })\n",
    "    \n",
    "    multiscale_df = pd.DataFrame(multiscale_effects)\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    for mouse in ['M1', 'M2']:\n",
    "        mouse_data = multiscale_df[multiscale_df.mouse == mouse]\n",
    "        ax.plot(mouse_data['scale_um'], mouse_data['cohens_d'], 'o-', linewidth=2, markersize=10,\n",
    "                label=f'{mouse}', alpha=0.8)\n",
    "    \n",
    "    # Mean across mice\n",
    "    mean_per_scale = multiscale_df.groupby('scale_um')['cohens_d'].mean()\n",
    "    ax.plot(mean_per_scale.index, mean_per_scale.values, 's-', linewidth=3, markersize=12,\n",
    "            color='black', label='Mean (n=2)', zorder=10)\n",
    "    \n",
    "    ax.axhline(0, color='gray', linewidth=1)\n",
    "    ax.axhline(2.0, color='red', linestyle='--', linewidth=1.5, alpha=0.5, label='Large effect threshold')\n",
    "    \n",
    "    ax.set_xlabel('Spatial Scale (Œºm)', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel(f'Cohen\\'s d for {top_marker}', fontweight='bold', fontsize=12)\n",
    "    ax.set_title(f'Panel C: Multi-Scale Coherence for {top_marker}\\n(Effect consistent across spatial resolutions?)',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks([10, 20, 40])\n",
    "    ax.set_xticklabels(['10 (cell-like)', '20 (micro-niche)', '40 (tissue-region)'])\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistics\n",
    "    scale_cv = multiscale_df.groupby('mouse')['cohens_d'].apply(lambda x: x.std() / abs(x.mean()) if x.mean() != 0 else np.nan)\n",
    "    print(f\"\\nüìä Multi-scale coherence:\")\n",
    "    print(f\"   - Effect direction consistent: {all(multiscale_df.groupby('mouse')['cohens_d'].apply(lambda x: all(np.sign(x) == np.sign(x.iloc[0]))))}\")\n",
    "    print(f\"   - Coefficient of variation across scales:\")\n",
    "    for mouse, cv in scale_cv.items():\n",
    "        print(f\"     ‚Ä¢ {mouse}: {cv:.2%}\")\n",
    "    print(f\"   - Interpretation: Low CV (<20%) = scale-robust, High CV (>50%) = scale-dependent\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  No large consistent effects to examine at multiple scales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: What Can We Claim?\n",
    "\n",
    "### ‚úÖ Legitimate Claims\n",
    "\n",
    "1. **Within-mouse consistency**: \"All ROIs within each mouse show consistent spatial patterns (median within-mouse |d| = X)\"\n",
    "2. **Between-mouse concordance**: \"Both biological replicates show effects in same direction for Y% of markers\"\n",
    "3. **Large effect sizes**: \"Observed effects are large (Cohen's d > 2.0) for markers A, B, C\"\n",
    "4. **Multi-scale robustness**: \"Effects consistent across 10-40Œºm spatial scales (CV < Z%)\"\n",
    "5. **Hypothesis generation**: \"These pilot findings (n=2) warrant validation in powered study (n‚â•6)\"\n",
    "\n",
    "### ‚ùå Illegitimate Claims\n",
    "\n",
    "1. ~~\"Statistically significant at p<0.05\"~~ ‚Üí Underpowered\n",
    "2. ~~\"Superpixels are independent replicates\"~~ ‚Üí Pseudo-replication\n",
    "3. ~~\"Generalizes to C57BL/6 population\"~~ ‚Üí n=2 insufficient\n",
    "4. ~~\"Hierarchical modeling increases power\"~~ ‚Üí Cannot estimate variance with n=2\n",
    "\n",
    "### üìù Paper Framing\n",
    "\n",
    "> \"This pilot study (n=2 mice per condition) demonstrates our hierarchical spatial analysis framework on real tissue. We assess effect consistency across biological replicates, technical replicates (ROIs within mouse), and spatial scales. While statistical power is limited by sample size (Cohen's d > 3.0 required for 80% power with n=2), we observe large, directionally-consistent effects for [specific markers]. These findings are hypothesis-generating and demonstrate the analytical pipeline's capability to extract biologically-interpretable spatial patterns from limited samples.\"\n",
    "\n",
    "**Key message**: We're demonstrating METHODS with pilot data, not making definitive BIOLOGICAL claims."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}